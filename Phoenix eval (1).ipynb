{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd3f1b50-ab3e-4f68-9cec-4e0d397d4c00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -Uq \"protobuf>=4.21.6\"  qdrant-client tiktoken \"arize-phoenix[evals,embeddings]\" \"openai>=1\" openinference-instrumentation-langchain litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28597f08-ac19-4fed-bafe-61d4361faa90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# %pip uninstall -y langchain langchain-core langchain-openai langchain-community langchain-groq langchain-text-splitters openinference-instrumentation-langchain\n",
    "\n",
    "%pip install --no-cache-dir \"langchain>=0.1.0,<0.4.0\"\n",
    "%pip install --no-cache-dir \"langchain-core>=0.1.0,<0.4.0\"\n",
    "%pip install --no-cache-dir \"langchain-openai>=0.0.2\"\n",
    "%pip install --no-cache-dir \"langchain-community>=0.0.10\"\n",
    "%pip install --no-cache-dir \"langchain-groq>=0.2.0\"\n",
    "%pip install --no-cache-dir \"langchain-text-splitters>=0.0.1\"\n",
    "%pip install --no-cache-dir \"openinference-instrumentation-langchain>=0.1.29\"\n",
    "\n",
    "dbutils.library.restartPython()\n",
    "\n",
    "# Verify installations (run after restart)\n",
    "%pip freeze | grep langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceda49ce-bec8-4135-bab2-933978ee03ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain: 0.3.10\nlangchain-community: 0.3.10\nlangchain-core: 0.3.22\nlangchain-groq: 0.2.1\nlangchain-openai: 0.2.11\nlangchain-text-splitters: 0.3.2\nopeninference-instrumentation-langchain: 0.1.29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages.ai import InputTokenDetails\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "# Print package versions to verify\n",
    "import pkg_resources\n",
    "packages = [\n",
    "    'langchain',\n",
    "    'langchain-community',\n",
    "    'langchain-core',\n",
    "    'langchain-groq',\n",
    "    'langchain-openai',\n",
    "    'langchain-text-splitters',\n",
    "    'openinference-instrumentation-langchain'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(package).version\n",
    "        print(f\"{package}: {version}\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"{package}: Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "182c5a58-c857-4926-97a0-3b05cd0d1ce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "from getpass import getpass\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "\n",
    "import phoenix as px\n",
    "from phoenix.otel import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d8f52ec-ac5d-4b6e-ad88-284a8995b197",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration and Initialization\n",
    "nest_asyncio.apply()\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Configure Groq API Key using dbutils\n",
    "try:\n",
    "    groq_api_key = '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'\n",
    "    os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
    "    os.environ[\"PHOENIX_PROJECT_NAME\"] = \"Phoenix_Capabilities_Testing\"\n",
    "    os.environ[\"AZURE_API_KEY\"] = \"38a6b22e0e4f43828877d844399faf4d\"\n",
    "    os.environ[\"AZURE_API_BASE\"] = \"https://ai-abhinavkatiyarai793972137108.openai.azure.com\" \n",
    "    os.environ[\"AZURE_API_VERSION\"] = \"2024-08-01-preview\"\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error accessing Groq API key from secrets. Please add it to the 'llm-keys' scope with key 'groq-api-key'\")\n",
    "    raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15e9bd4d-5772-4e94-a707-079066909699",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configure embeddings using SentenceTransformers\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "\n",
    "def load_documents(directory_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.txt'):  \n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            loader = TextLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "documents = load_documents('/Workspace/Users/abhinav.katiyar@spaceinventive.com/data/')\n",
    "\n",
    "# Create text splitter for smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Process documents into chunks\n",
    "all_chunks = []\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    valid_chunks = [chunk for chunk in chunks if len(chunk) > 100]\n",
    "    all_chunks.extend(valid_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c436b95-baa0-4885-b607-af63e8979359",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build vector store\n",
    "qdrant = Qdrant.from_texts(\n",
    "    all_chunks,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"my_documents\",\n",
    ")\n",
    "\n",
    "# Configure retriever\n",
    "retriever = qdrant.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 2,\n",
    "        \"fetch_k\": 3\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure Groq for question generation\n",
    "question_llm = ChatGroq(\n",
    "    model_name=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=512,\n",
    "    streaming=False\n",
    ")\n",
    "\n",
    "# Configure Groq for QA\n",
    "qa_llm = ChatGroq(\n",
    "    model_name=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1024,\n",
    "    streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e2a1363-a41b-4b68-8792-ca276bbf4be5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/1857/command-4402110491910854-926698858:45: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  question_chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Question Generation Template\n",
    "# generate_questions_template = \"\"\"Create exactly 3 questions based on this text. Only return a JSON object.\n",
    "\n",
    "# TEXT TO ANALYZE:\n",
    "# {text}\n",
    "\n",
    "# RESPONSE FORMAT:\n",
    "# {{\n",
    "# \"question_1\": \"Write your first question here\",\n",
    "# \"question_2\": \"Write your second question here\",\n",
    "# \"question_3\": \"Write your third question here\"\n",
    "# }}\n",
    "\n",
    "# IMPORTANT: Only return the JSON object, no additional text.\"\"\"\n",
    "\n",
    "generate_questions_template = \"\"\"\\\n",
    "Context information is below.\n",
    "\n",
    "---------------------\n",
    "{text}\n",
    "---------------------\n",
    "\n",
    "Given the context information and not prior knowledge.\n",
    "generate only questions based on the below query.\n",
    "\n",
    "You are a Teacher/ Professor. Your task is to setup \\\n",
    "3 questions for an upcoming \\\n",
    "quiz/examination. The questions should be diverse in nature \\\n",
    "across the document. Restrict the questions to the \\\n",
    "context information provided.\"\n",
    "\n",
    "Output the questions in JSON format with the keys question_1, question_2, question_3.\n",
    "\"\"\"\n",
    "\n",
    "# QA Template\n",
    "qa_prompt_template = \"\"\"Answer the following question based on the given context. Be concise.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "# Create chains\n",
    "question_chain = LLMChain(\n",
    "    llm=question_llm,\n",
    "    prompt=PromptTemplate(\n",
    "        template=generate_questions_template,\n",
    "        input_variables=[\"text\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=qa_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": PromptTemplate(\n",
    "            template=qa_prompt_template,\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e99d572f-6ac3-4808-81e9-59d6cc37feb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "session = px.active_session()\n",
    "print(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e318aefa-b642-4f26-8247-c97fca837489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tracer_provider = register()\n",
    "LangChainInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)\n",
    "\n",
    "# Launch Phoenix\n",
    "session = px.launch_app()\n",
    "print(f\"Phoenix UI available at: {session.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f70c4b71-0f74-49ce-b57b-37f89d51ebe9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 07:16:18 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:558: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\"\n2024/12/09 07:16:19 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/tracing/utils/__init__.py:53: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n\nFor example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\nwith: `from pydantic import BaseModel`\nor the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What information is available in the context?\nThe context provides information about a regulation related to autonomous actions affecting certain systems (Category A systems) in the context of AI. It mentions that operators must maintain comprehensive documentation of decision paths for these autonomous actions. However, it does not provide information about philosophical questions, regulatory compliance across multiple jurisdictions, or impact on market dynamics and competitive positioning.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-0b4e802958a843c681c5bf1d5b81339f\"",
      "text/plain": [
       "Trace(request_id=tr-0b4e802958a843c681c5bf1d5b81339f)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"What information is available in the context?\"\n",
    "\n",
    "response = qa_chain({\"query\": question})\n",
    "print(response['query'])\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9812e7d2-ccac-451d-8a48-1d6553f04e65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['name', 'span_kind', 'parent_id', 'start_time', 'end_time',\n",
       "       'status_code', 'status_message', 'events', 'context.span_id',\n",
       "       'context.trace_id', 'attributes.openinference.span.kind',\n",
       "       'attributes.output.value', 'attributes.metadata',\n",
       "       'attributes.input.value', 'attributes.output.mime_type',\n",
       "       'attributes.retrieval.documents',\n",
       "       'attributes.llm.token_count.completion', 'attributes.input.mime_type',\n",
       "       'attributes.llm.token_count.total', 'attributes.llm.token_count.prompt',\n",
       "       'attributes.llm.input_messages', 'attributes.llm.output_messages',\n",
       "       'attributes.llm.invocation_parameters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "926fc824-ad7a-4682-b8fc-5f785242d5d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>span_kind</th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>attributes.retrieval.documents</th>\n",
       "      <th>attributes.llm.output_messages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e6e8a53c4fc30767</th>\n",
       "      <td>VectorStoreRetriever</td>\n",
       "      <td>RETRIEVER</td>\n",
       "      <td>What information is available in the context?</td>\n",
       "      <td>[{'document.content': '. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).', 'document.metadata': {'_id': '72cd6582f98344139138a689b4c4a13f', '_collection_name': 'my_documents'}}, {'document.content': '2. Philosophical questions about AI agency and responsibility\n",
       "3. Regulatory compliance across multiple jurisdictions\n",
       "4. Impact on market dynamics and competitive positioning', 'document.metadata': {'_id': 'ddef3f0b37484073a21ca25eb25e4c5c', '_collection_name': 'my_documents'}}]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d0759506f03a046e</th>\n",
       "      <td>ChatGroq</td>\n",
       "      <td>LLM</td>\n",
       "      <td>{\"messages\": [[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"Answer the following question based on the given context. Be concise.\\n\\nContext: . Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).\\n\\n2. Philosophical questions about AI agency and responsibility\\n3. Regulatory compliance across multiple jurisdictions\\n4. Impact on market dynamics and competitive positioning\\n\\nQuestion: What information is available in the context?\\n\\nAnswer:\", \"type\": \"human\"}}]]}</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'message.role': 'assistant', 'message.content': 'The context provides information about a regulation related to autonomous actions affecting certain systems (Category A systems) in the context of AI. It mentions that operators must maintain comprehensive documentation of decision paths for these autonomous actions. However, it does not provide information about philosophical questions, regulatory compliance across multiple jurisdictions, or impact on market dynamics and competitive positioning.'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            attributes.llm.output_messages\n",
       "context.span_id                         ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "e6e8a53c4fc30767  VectorStoreRetriever  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      None\n",
       "d0759506f03a046e              ChatGroq  ...  [{'message.role': 'assistant', 'message.content': 'The context provides information about a regulation related to autonomous actions affecting certain systems (Category A systems) in the context of AI. It mentions that operators must maintain comprehensive documentation of decision paths for these autonomous actions. However, it does not provide information about philosophical questions, regulatory compliance across multiple jurisdictions, or impact on market dynamics and competitive positioning.'}]\n",
       "\n",
       "[2 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans_df = px.Client().get_spans_dataframe()\n",
    "spans_df[[\"name\", \"span_kind\", \"attributes.input.value\", \"attributes.retrieval.documents\",\"attributes.llm.output_messages\"]].head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c989f7af-01a3-42a5-bedc-165ddfa4c954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sampled_chunks = pd.DataFrame({\"text\": all_chunks})\n",
    "sample_size = min(4, len(sampled_chunks))\n",
    "sampled_chunks = sampled_chunks.sample(n=sample_size, random_state=42)\n",
    "\n",
    "def clean_and_parse_response(response_text):\n",
    "    \"\"\"Clean and parse the response text into valid JSON.\"\"\"\n",
    "    try:\n",
    "        cleaned = response_text.strip()\n",
    "        start = cleaned.find('{')\n",
    "        end = cleaned.rfind('}')\n",
    "        \n",
    "        if start != -1 and end != -1:\n",
    "            cleaned = cleaned[start:end+1]\n",
    "        \n",
    "        result = json.loads(cleaned)\n",
    "        \n",
    "        required_keys = ['question_1', 'question_2', 'question_3']\n",
    "        if not all(key in result for key in required_keys):\n",
    "            raise ValueError(\"Missing required question keys\")\n",
    "            \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Parsing error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Generate questions\n",
    "questions = []\n",
    "for idx, row in sampled_chunks.iterrows():\n",
    "    try:\n",
    "        chunk_text = row['text'][:500]  # Limit chunk size\n",
    "        \n",
    "        response = question_chain.invoke({\"text\": chunk_text})\n",
    "        parsed = clean_and_parse_response(response['text'])\n",
    "        \n",
    "        questions.append({\n",
    "            \"text\": row['text'],  # Keep the original text chunk\n",
    "            \"question_1\": parsed['question_1'],\n",
    "            \"question_2\": parsed['question_2'],\n",
    "            \"question_3\": parsed['question_3']\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process chunk {idx + 1}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Create questions dataframe\n",
    "questions_df = pd.DataFrame(questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e015a46e-b820-4358-bb65-4e45af9f83d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# LLM_Generate by Phoneix (provide dby phoenix to generate questions)\n",
    "import json\n",
    "\n",
    "from phoenix.evals import OpenAIModel, llm_generate\n",
    "\n",
    "\n",
    "def output_parser(response: str, index: int):\n",
    "    try:\n",
    "        return json.loads(response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\"__error__\": str(e)}\n",
    "\n",
    "\n",
    "questions_df = llm_generate(\n",
    "    dataframe=document_chunks_df,\n",
    "    template=generate_questions_template,\n",
    "    model=OpenAIModel(model=\"gpt-3.5-turbo\"),\n",
    "    output_parser=output_parser,\n",
    "    concurrency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfbeb54c-5938-4453-9712-7407d7ec785c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from phoenix.evals import LiteLLMModel, llm_generate\n",
    "\n",
    "sampled_chunks = pd.DataFrame({\"text\": all_chunks})\n",
    "sample_size = min(5, len(sampled_chunks))\n",
    "sampled_chunks = sampled_chunks.sample(n=sample_size, random_state=42)\n",
    "\n",
    "\n",
    "def output_parser(response: str, index: int):\n",
    "    try:\n",
    "        return json.loads(response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\"__error__\": str(e)}\n",
    "\n",
    "questions_df = llm_generate(\n",
    "    dataframe=sampled_chunks,\n",
    "    template=generate_questions_template,\n",
    "    model=LiteLLMModel(model=\"azure/gpt-35-turbo\"),\n",
    "    output_parser=output_parser,\n",
    "    concurrency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d9f1f1a-3570-4b9c-ad98-8846bb39b8c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>question_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "      <td>According to the context information, what is the implication of consciousness being primary?</td>\n",
       "      <td>Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What is the 'substantial factor' test and which courts have adopted it?</td>\n",
       "      <td>What is the traditional causation standard for algorithmic influence assessment and how has it been modified?</td>\n",
       "      <td>What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the perspective proposed by some theorists regarding consciousness and reality?</td>\n",
       "      <td>How does the perspective of consciousness being fundamental to reality challenge materialist and dualist frameworks?</td>\n",
       "      <td>What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "      <td>What is the definition of Category A systems as per Appendix II-B?</td>\n",
       "      <td>What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?</td>\n",
       "      <td>What are strong interactions in the context of quantum chromodynamics (QCD)?</td>\n",
       "      <td>What is the role of quarks and gluons in quantum chromodynamics (QCD)?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              question_1  ...                                                                                                                                                                          question_3\n",
       "9                                                                     What is the participatory anthropic principle proposed by Wheeler?  ...                                                    Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.\n",
       "25                                                               What is the 'substantial factor' test and which courts have adopted it?  ...                                                                                  What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?\n",
       "8                                                What is the perspective proposed by some theorists regarding consciousness and reality?  ...                                                                   What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?\n",
       "21  What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?  ...  What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?\n",
       "0                                                        What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?  ...                                                                                                              What is the role of quarks and gluons in quantum chromodynamics (QCD)?\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50a0528e-b294-4b68-aaf7-7297be4013d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Construct a dataframe of the questions and the document chunks\n",
    "questions_with_document_chunk_df = pd.concat([questions_df, sampled_chunks], axis=1)\n",
    "questions_with_document_chunk_df = questions_with_document_chunk_df.melt(\n",
    "    id_vars=[\"text\"], value_name=\"question\"\n",
    ").drop(\"variable\", axis=1)\n",
    "# If the above step was interrupted, there might be questions missing. Let's run this to clean up the dataframe.\n",
    "questions_with_document_chunk_df = questions_with_document_chunk_df[\n",
    "    questions_with_document_chunk_df[\"question\"].notnull()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e46ad25-70ab-4e03-bbba-7aa751594f29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states</td>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>. Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"</td>\n",
       "      <td>What is the 'substantial factor' test and which courts have adopted it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>. Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.</td>\n",
       "      <td>What is the perspective proposed by some theorists regarding consciousness and reality?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).</td>\n",
       "      <td>What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons</td>\n",
       "      <td>What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states</td>\n",
       "      <td>According to the context information, what is the implication of consciousness being primary?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>. Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"</td>\n",
       "      <td>What is the traditional causation standard for algorithmic influence assessment and how has it been modified?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>. Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.</td>\n",
       "      <td>How does the perspective of consciousness being fundamental to reality challenge materialist and dualist frameworks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).</td>\n",
       "      <td>What is the definition of Category A systems as per Appendix II-B?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons</td>\n",
       "      <td>What are strong interactions in the context of quantum chromodynamics (QCD)?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states</td>\n",
       "      <td>Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>. Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"</td>\n",
       "      <td>What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>. Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.</td>\n",
       "      <td>What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).</td>\n",
       "      <td>What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons</td>\n",
       "      <td>What is the role of quarks and gluons in quantum chromodynamics (QCD)?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                            text                                                                                                                                                                            question\n",
       "0   Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states                                                                                                                  What is the participatory anthropic principle proposed by Wheeler?\n",
       "1                            . Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"                                                                                                             What is the 'substantial factor' test and which courts have adopted it?\n",
       "2                                                                              . Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.                                                                                             What is the perspective proposed by some theorists regarding consciousness and reality?\n",
       "3                                                                  . Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).                                                What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?\n",
       "4                                                                                    The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons                                                                                                     What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?\n",
       "5   Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states                                                                                       According to the context information, what is the implication of consciousness being primary?\n",
       "6                            . Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"                                                                       What is the traditional causation standard for algorithmic influence assessment and how has it been modified?\n",
       "7                                                                              . Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.                                                                How does the perspective of consciousness being fundamental to reality challenge materialist and dualist frameworks?\n",
       "8                                                                  . Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).                                                                                                                  What is the definition of Category A systems as per Appendix II-B?\n",
       "9                                                                                    The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons                                                                                                        What are strong interactions in the context of quantum chromodynamics (QCD)?\n",
       "10  Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states                                                    Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.\n",
       "11                           . Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"                                                                                  What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?\n",
       "12                                                                             . Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.                                                                   What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?\n",
       "13                                                                 . Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).  What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?\n",
       "14                                                                                   The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons                                                                                                              What is the role of quarks and gluons in quantum chromodynamics (QCD)?"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_with_document_chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9739580-dbc9-4070-a5f1-65384ae4fac2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# questions_df\n",
    "# questions_with_document_chunk_df = questions_df.melt(\n",
    "#     id_vars=[\"text\"], value_name=\"question\"\n",
    "# ).drop(\"variable\", axis=1)\n",
    "# # If the above step was interrupted, there might be questions missing. Let's run this to clean up the dataframe.\n",
    "# questions_with_document_chunk_df = questions_with_document_chunk_df[\n",
    "#     questions_with_document_chunk_df[\"question\"].notnull()\n",
    "# ]\n",
    "# questions_with_document_chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21d8bc20-3ac9-484e-8089-6b3a7c8982f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(15, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_with_document_chunk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7499ae68-9459-405d-8ddc-de79e9269c58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_qa_pairs(questions_df, retriever, qa_chain, max_context_length=1000, docs_per_question=2):\n",
    "    \"\"\"\n",
    "    Generate question-answer pairs with retrieved context.\n",
    "    \n",
    "    Args:\n",
    "        questions_df (pd.DataFrame): DataFrame containing questions with 'text' and 'question' columns\n",
    "        retriever: Document retriever instance\n",
    "        qa_chain: QA chain instance\n",
    "        max_context_length (int): Maximum length for context\n",
    "        docs_per_question (int): Number of documents to use for context\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing QA pairs with context\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    total_questions = len(questions_df)\n",
    "    \n",
    "    if questions_df.empty:\n",
    "        print(\"No questions to process!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    for idx, row in questions_df.iterrows():\n",
    "        try:\n",
    "            question = row['question']\n",
    "            print(f\"\\nProcessing question {idx + 1}/{total_questions}:\")\n",
    "            print(f\"Question: {question}\")\n",
    "            \n",
    "            # Retrieve relevant documents\n",
    "            relevant_docs = retriever.get_relevant_documents(question)\n",
    "            context = \" \".join([doc.page_content for doc in relevant_docs[:docs_per_question]])\n",
    "            \n",
    "            # Truncate context if needed\n",
    "            if len(context) > max_context_length:\n",
    "                context = context[:max_context_length] + \"...\"\n",
    "            \n",
    "            # Generate answer - using 'query' instead of 'question'\n",
    "            response = qa_chain({\n",
    "                \"query\": question\n",
    "            })\n",
    "            \n",
    "            # Store results\n",
    "            qa_pair = {\n",
    "                \"text\": row['text'],\n",
    "                \"question\": question,\n",
    "                \"answer\": response[\"result\"],\n",
    "                \"context\": context,\n",
    "                \"context_length\": len(context)\n",
    "            }\n",
    "            \n",
    "            print(f\"Answer: {qa_pair['answer'][:100]}...\")  # Print first 100 chars of answer\n",
    "            qa_pairs.append(qa_pair)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {idx + 1}: {str(e)}\")\n",
    "            # Add error entry to maintain data consistency\n",
    "            qa_pairs.append({\n",
    "                \"text\": row['text'],\n",
    "                \"question\": question,\n",
    "                \"answer\": f\"Error generating answer: {str(e)}\",\n",
    "                \"context\": \"\",\n",
    "                \"context_length\": 0\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Print progress\n",
    "        if (idx + 1) % 5 == 0:\n",
    "            print(f\"\\nCompleted {idx + 1}/{total_questions} questions\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    qa_df = pd.DataFrame(qa_pairs)\n",
    "    \n",
    "    # Add quality metrics\n",
    "    qa_df['answer_length'] = qa_df['answer'].str.len()\n",
    "    qa_df['question_length'] = qa_df['question'].str.len()\n",
    "    \n",
    "    print(f\"\\nProcessing complete! Generated {len(qa_df)} QA pairs\")\n",
    "    \n",
    "    return qa_df\n",
    "\n",
    "# Generate QA pairs\n",
    "qa_df = generate_qa_pairs(\n",
    "    questions_df=questions_with_document_chunk_df,\n",
    "    retriever=retriever,\n",
    "    qa_chain=qa_chain,\n",
    "    max_context_length=1000,\n",
    "    docs_per_question=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c3b8e5-d05c-4809-aafe-0f0a543bde4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>input</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th>document_position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e6e8a53c4fc30767</th>\n",
       "      <th>0</th>\n",
       "      <td>c4493a2c76d3cfdf1f2e7e43fdbc04ec</td>\n",
       "      <td>What information is available in the context?</td>\n",
       "      <td>. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4493a2c76d3cfdf1f2e7e43fdbc04ec</td>\n",
       "      <td>What information is available in the context?</td>\n",
       "      <td>2. Philosophical questions about AI agency and responsibility\\n3. Regulatory compliance across multiple jurisdictions\\n4. Impact on market dynamics and competitive positioning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">950905a084b6365b</th>\n",
       "      <th>0</th>\n",
       "      <td>e83918b83b3d9d19d8884b8abc9ba4c9</td>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "      <td>Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e83918b83b3d9d19d8884b8abc9ba4c9</td>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "      <td>. Yet this illusion appears necessary for practical functioning, creating a paradox where we must simultaneously accept and reject our apparent individuality.\"\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2c055f2dee5930a2</th>\n",
       "      <th>0</th>\n",
       "      <td>cdafdddcaa58e22e9c3ca97c5dd3dcaf</td>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "      <td>Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011046270e48ea3</th>\n",
       "      <th>1</th>\n",
       "      <td>ff84746664c13153e2aeeb2c34bc7af0</td>\n",
       "      <td>What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "      <td>However, the interpretation of \"reasonable foreseeability\" under Article 12.4 remains contested, particularly in cases where multiple AI systems interact through standardized APIs. The precedent established in TechCorp v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">c1bc0ee3b32d457d</th>\n",
       "      <th>0</th>\n",
       "      <td>ad4726fbd2e6dcba3775cb3ce6097ba9</td>\n",
       "      <td>What is the role of quarks and gluons in quantum chromodynamics (QCD)?</td>\n",
       "      <td>The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ad4726fbd2e6dcba3775cb3ce6097ba9</td>\n",
       "      <td>What is the role of quarks and gluons in quantum chromodynamics (QCD)?</td>\n",
       "      <td>The Higgs mechanism, while separate from QCD, plays a crucial role through spontaneous symmetry breaking. This process generates masses for the W and Z bosons while leaving the photon massless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">065a5b74f19a8ee0</th>\n",
       "      <th>0</th>\n",
       "      <td>2be295e356d05d77174034ae056df0f3</td>\n",
       "      <td>What is the role of quarks and gluons in quantum chromodynamics (QCD)?</td>\n",
       "      <td>The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2be295e356d05d77174034ae056df0f3</td>\n",
       "      <td>What is the role of quarks and gluons in quantum chromodynamics (QCD)?</td>\n",
       "      <td>The Higgs mechanism, while separate from QCD, plays a crucial role through spontaneous symmetry breaking. This process generates masses for the W and Z bosons while leaving the photon massless</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    context.trace_id  ...                                                                                                                                                                                                                                                     reference\n",
       "context.span_id  document_position                                    ...                                                                                                                                                                                                                                                              \n",
       "e6e8a53c4fc30767 0                  c4493a2c76d3cfdf1f2e7e43fdbc04ec  ...                                                                 . Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).\n",
       "                 1                  c4493a2c76d3cfdf1f2e7e43fdbc04ec  ...                                                                               2. Philosophical questions about AI agency and responsibility\\n3. Regulatory compliance across multiple jurisdictions\\n4. Impact on market dynamics and competitive positioning\n",
       "950905a084b6365b 0                  e83918b83b3d9d19d8884b8abc9ba4c9  ...  Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states\n",
       "                 1                  e83918b83b3d9d19d8884b8abc9ba4c9  ...                                                                                             . Yet this illusion appears necessary for practical functioning, creating a paradox where we must simultaneously accept and reject our apparent individuality.\"\"\"\n",
       "2c055f2dee5930a2 0                  cdafdddcaa58e22e9c3ca97c5dd3dcaf  ...  Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states\n",
       "...                                                              ...  ...                                                                                                                                                                                                                                                           ...\n",
       "1011046270e48ea3 1                  ff84746664c13153e2aeeb2c34bc7af0  ...                                  However, the interpretation of \"reasonable foreseeability\" under Article 12.4 remains contested, particularly in cases where multiple AI systems interact through standardized APIs. The precedent established in TechCorp v\n",
       "c1bc0ee3b32d457d 0                  ad4726fbd2e6dcba3775cb3ce6097ba9  ...                                                                                   The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons\n",
       "                 1                  ad4726fbd2e6dcba3775cb3ce6097ba9  ...                                                              The Higgs mechanism, while separate from QCD, plays a crucial role through spontaneous symmetry breaking. This process generates masses for the W and Z bosons while leaving the photon massless\n",
       "065a5b74f19a8ee0 0                  2be295e356d05d77174034ae056df0f3  ...                                                                                   The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons\n",
       "                 1                  2be295e356d05d77174034ae056df0f3  ...                                                              The Higgs mechanism, while separate from QCD, plays a crucial role through spontaneous symmetry breaking. This process generates masses for the W and Z bosons while leaving the photon massless\n",
       "\n",
       "[62 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.session.evaluation import get_retrieved_documents\n",
    "\n",
    "retrieved_documents_df = get_retrieved_documents(px.Client())\n",
    "retrieved_documents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50cac5f6-ac25-408c-9b93-5d369bf7cc19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import phoenix.evals\n",
    "\n",
    "module_attrs = dir(phoenix.evals)\n",
    "\n",
    "module_classes = [attr for attr in module_attrs if isinstance(getattr(phoenix.evals, attr), type)]\n",
    "print(\"Classes available in phoenix.evals:\")\n",
    "for cls in module_classes:\n",
    "    print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e060ded-3f86-40fe-886f-f3f41e1f95f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter your Gemini API key:  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from phoenix.evals import (\n",
    "    RelevanceEvaluator,\n",
    "    run_evals,\n",
    "    LiteLLMModel\n",
    ")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if not (gemini_api_key := os.getenv(\"GEMINI_API_KEY\")):\n",
    "    gemini_api_key = input(\"Enter your Gemini API key: \")\n",
    "os.environ[\"GEMINI_API_KEY\"] = gemini_api_key\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(LiteLLMModel(\n",
    "    model=\"gemini/gemini-pro\"\n",
    "))\n",
    "\n",
    "\n",
    "retrieved_documents_relevance_df = run_evals(\n",
    "    evaluators=[relevance_evaluator],\n",
    "    dataframe=retrieved_documents_df,\n",
    "    provide_explanation=True,\n",
    "    concurrency=5\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "202850a0-5ba8-4b37-a7a0-9bc57e76da74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from phoenix.evals import (\n",
    "    RelevanceEvaluator,\n",
    "    run_evals,\n",
    "    LiteLLMModel\n",
    ")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(LiteLLMModel(\n",
    "    model=\"azure/gpt-35-turbo\"\n",
    "))\n",
    "\n",
    "retrieved_documents_relevance_df = run_evals(\n",
    "    evaluators=[relevance_evaluator],\n",
    "    dataframe=retrieved_documents_df,\n",
    "    provide_explanation=True,\n",
    "    concurrency=5\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4ab0fa4-277d-4aaf-88eb-5a9838decb4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th>document_position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e6e8a53c4fc30767</th>\n",
       "      <th>0</th>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text mentions that operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems. However, it does not provide any specific information about what information is available in the context. Therefore, the reference text is unrelated to the question.\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text lists three topics: philosophical questions about AI agency and responsibility, regulatory compliance across multiple jurisdictions, and impact on market dynamics and competitive positioning. None of these topics directly answer the question of what information is available in the context. Therefore, the label is \"unrelated\". \\n\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">950905a084b6365b</th>\n",
       "      <th>0</th>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text does not contain any information about the participatory anthropic principle proposed by Wheeler. It discusses an illusion related to individuality, but this is not relevant to the question.\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2c055f2dee5930a2</th>\n",
       "      <th>0</th>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        label  ...                                                                                                                                                                                                                                                                                                                                                                      explanation\n",
       "context.span_id  document_position             ...                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "e6e8a53c4fc30767 0                  unrelated  ...                          The reference text mentions that operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems. However, it does not provide any specific information about what information is available in the context. Therefore, the reference text is unrelated to the question.\\nLABEL: unrelated\n",
       "                 1                  unrelated  ...  The reference text lists three topics: philosophical questions about AI agency and responsibility, regulatory compliance across multiple jurisdictions, and impact on market dynamics and competitive positioning. None of these topics directly answer the question of what information is available in the context. Therefore, the label is \"unrelated\". \\n\\nLABEL: unrelated\n",
       "950905a084b6365b 0                   relevant  ...                 The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant\n",
       "                 1                  unrelated  ...                                                                                                                                              The reference text does not contain any information about the participatory anthropic principle proposed by Wheeler. It discusses an illusion related to individuality, but this is not relevant to the question.\\nLABEL: unrelated\n",
       "2c055f2dee5930a2 0                   relevant  ...                 The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents_relevance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5101190e-5947-4924-9e2f-002eee918162",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "documents_with_relevance_df = pd.concat(\n",
    "    [retrieved_documents_df, retrieved_documents_relevance_df.add_prefix(\"eval_\")], axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad7f2d56-af03-46b1-9e1b-6b0f9d3a59b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>input</th>\n",
       "      <th>reference</th>\n",
       "      <th>eval_label</th>\n",
       "      <th>eval_score</th>\n",
       "      <th>eval_explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th>document_position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e6e8a53c4fc30767</th>\n",
       "      <th>0</th>\n",
       "      <td>c4493a2c76d3cfdf1f2e7e43fdbc04ec</td>\n",
       "      <td>What information is available in the context?</td>\n",
       "      <td>. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text mentions that operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems. However, it does not provide any specific information about what information is available in the context. Therefore, the reference text is unrelated to the question.\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4493a2c76d3cfdf1f2e7e43fdbc04ec</td>\n",
       "      <td>What information is available in the context?</td>\n",
       "      <td>2. Philosophical questions about AI agency and responsibility\\n3. Regulatory compliance across multiple jurisdictions\\n4. Impact on market dynamics and competitive positioning</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text lists three topics: philosophical questions about AI agency and responsibility, regulatory compliance across multiple jurisdictions, and impact on market dynamics and competitive positioning. None of these topics directly answer the question of what information is available in the context. Therefore, the label is \"unrelated\". \\n\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">950905a084b6365b</th>\n",
       "      <th>0</th>\n",
       "      <td>e83918b83b3d9d19d8884b8abc9ba4c9</td>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "      <td>Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e83918b83b3d9d19d8884b8abc9ba4c9</td>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "      <td>. Yet this illusion appears necessary for practical functioning, creating a paradox where we must simultaneously accept and reject our apparent individuality.\"\"\"</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text does not contain any information about the participatory anthropic principle proposed by Wheeler. It discusses an illusion related to individuality, but this is not relevant to the question.\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    context.trace_id  ...                                                                                                                                                                                                                                                                                                                                                                 eval_explanation\n",
       "context.span_id  document_position                                    ...                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "e6e8a53c4fc30767 0                  c4493a2c76d3cfdf1f2e7e43fdbc04ec  ...                          The reference text mentions that operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems. However, it does not provide any specific information about what information is available in the context. Therefore, the reference text is unrelated to the question.\\nLABEL: unrelated\n",
       "                 1                  c4493a2c76d3cfdf1f2e7e43fdbc04ec  ...  The reference text lists three topics: philosophical questions about AI agency and responsibility, regulatory compliance across multiple jurisdictions, and impact on market dynamics and competitive positioning. None of these topics directly answer the question of what information is available in the context. Therefore, the label is \"unrelated\". \\n\\nLABEL: unrelated\n",
       "950905a084b6365b 0                  e83918b83b3d9d19d8884b8abc9ba4c9  ...                 The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant\n",
       "                 1                  e83918b83b3d9d19d8884b8abc9ba4c9  ...                                                                                                                                              The reference text does not contain any information about the participatory anthropic principle proposed by Wheeler. It discusses an illusion related to individuality, but this is not relevant to the question.\\nLABEL: unrelated\n",
       "\n",
       "[4 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_with_relevance_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce83befd-46da-4e48-abbd-82d04e100efc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4402110491910889>, line 18\u001B[0m\n",
       "\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n",
       "\u001B[1;32m     14\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan\n",
       "\u001B[1;32m     17\u001B[0m ndcg_at_2 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\n",
       "\u001B[0;32m---> 18\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m: documents_with_relevance_df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext.span_id\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mapply(_compute_ndcg, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)}\n",
       "\u001B[1;32m     19\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1588\u001B[0m, in \u001B[0;36mGroupBy.apply\u001B[0;34m(self, func, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1580\u001B[0m             new_msg \u001B[38;5;241m=\u001B[39m (\n",
       "\u001B[1;32m   1581\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe operation \u001B[39m\u001B[38;5;132;01m{\u001B[39;00morig_func\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m failed on a column. If any error \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1582\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis raised, this will raise an exception in a future version \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1583\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof pandas. Drop these columns to avoid this warning.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1584\u001B[0m             )\n",
       "\u001B[1;32m   1585\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m rewrite_warning(\n",
       "\u001B[1;32m   1586\u001B[0m                 old_msg, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, new_msg\n",
       "\u001B[1;32m   1587\u001B[0m             ) \u001B[38;5;28;01mif\u001B[39;00m is_np_func \u001B[38;5;28;01melse\u001B[39;00m nullcontext():\n",
       "\u001B[0;32m-> 1588\u001B[0m                 \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_python_apply_general(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selected_obj)\n",
       "\u001B[1;32m   1590\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1629\u001B[0m, in \u001B[0;36mGroupBy._python_apply_general\u001B[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001B[0m\n",
       "\u001B[1;32m   1592\u001B[0m \u001B[38;5;129m@final\u001B[39m\n",
       "\u001B[1;32m   1593\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_python_apply_general\u001B[39m(\n",
       "\u001B[1;32m   1594\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1599\u001B[0m     is_agg: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m   1600\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NDFrameT:\n",
       "\u001B[1;32m   1601\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m   1602\u001B[0m \u001B[38;5;124;03m    Apply function f in python space\u001B[39;00m\n",
       "\u001B[1;32m   1603\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1627\u001B[0m \u001B[38;5;124;03m        data after applying f\u001B[39;00m\n",
       "\u001B[1;32m   1628\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 1629\u001B[0m     values, mutated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrouper\u001B[38;5;241m.\u001B[39mapply(f, data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis)\n",
       "\u001B[1;32m   1630\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m not_indexed_same \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m   1631\u001B[0m         not_indexed_same \u001B[38;5;241m=\u001B[39m mutated \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmutated\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/ops.py:839\u001B[0m, in \u001B[0;36mBaseGrouper.apply\u001B[0;34m(self, f, data, axis)\u001B[0m\n",
       "\u001B[1;32m    837\u001B[0m \u001B[38;5;66;03m# group might be modified\u001B[39;00m\n",
       "\u001B[1;32m    838\u001B[0m group_axes \u001B[38;5;241m=\u001B[39m group\u001B[38;5;241m.\u001B[39maxes\n",
       "\u001B[0;32m--> 839\u001B[0m res \u001B[38;5;241m=\u001B[39m f(group)\n",
       "\u001B[1;32m    840\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mutated \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_indexed_like(res, group_axes, axis):\n",
       "\u001B[1;32m    841\u001B[0m     mutated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1540\u001B[0m, in \u001B[0;36mGroupBy.apply.<locals>.f\u001B[0;34m(g)\u001B[0m\n",
       "\u001B[1;32m   1537\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n",
       "\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf\u001B[39m(g):\n",
       "\u001B[1;32m   1539\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[0;32m-> 1540\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(g, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\n",
       "File \u001B[0;32m<command-4402110491910889>, line 12\u001B[0m, in \u001B[0;36m_compute_ndcg\u001B[0;34m(df, k)\u001B[0m\n",
       "\u001B[1;32m     10\u001B[0m eval_scores[: \u001B[38;5;28mlen\u001B[39m(df)] \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39meval_score\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ndcg_score([eval_scores], k\u001B[38;5;241m=\u001B[39mk)\n",
       "\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n",
       "\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:580\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    578\u001B[0m     patch_function\u001B[38;5;241m.\u001B[39mcall(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 580\u001B[0m     patch_function(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    582\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    584\u001B[0m try_log_autologging_event(\n",
       "\u001B[1;32m    585\u001B[0m     AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_patch_function_success,\n",
       "\u001B[1;32m    586\u001B[0m     session,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    590\u001B[0m     kwargs,\n",
       "\u001B[1;32m    591\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/sklearn/__init__.py:1718\u001B[0m, in \u001B[0;36m_autolog.<locals>.patched_metric_api\u001B[0;34m(original, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1714\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mshould_log_post_training_metrics():\n",
       "\u001B[1;32m   1715\u001B[0m     \u001B[38;5;66;03m# one metric api may call another metric api,\u001B[39;00m\n",
       "\u001B[1;32m   1716\u001B[0m     \u001B[38;5;66;03m# to avoid this, call disable_log_post_training_metrics to avoid nested patch\u001B[39;00m\n",
       "\u001B[1;32m   1717\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mdisable_log_post_training_metrics():\n",
       "\u001B[0;32m-> 1718\u001B[0m         metric \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m   1720\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mis_metric_value_loggable(metric):\n",
       "\u001B[1;32m   1721\u001B[0m         metric_name \u001B[38;5;241m=\u001B[39m original\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:561\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n",
       "\u001B[1;32m    558\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n",
       "\u001B[1;32m    559\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
       "\u001B[0;32m--> 561\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:496\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n",
       "\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m    488\u001B[0m     try_log_autologging_event(\n",
       "\u001B[1;32m    489\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_start,\n",
       "\u001B[1;32m    490\u001B[0m         session,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    494\u001B[0m         og_kwargs,\n",
       "\u001B[1;32m    495\u001B[0m     )\n",
       "\u001B[0;32m--> 496\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m original_fn(\u001B[38;5;241m*\u001B[39mog_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mog_kwargs)\n",
       "\u001B[1;32m    498\u001B[0m     try_log_autologging_event(\n",
       "\u001B[1;32m    499\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_success,\n",
       "\u001B[1;32m    500\u001B[0m         session,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    504\u001B[0m         og_kwargs,\n",
       "\u001B[1;32m    505\u001B[0m     )\n",
       "\u001B[1;32m    506\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:558\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n",
       "\u001B[1;32m    550\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n",
       "\u001B[1;32m    551\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n",
       "\u001B[1;32m    552\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n",
       "\u001B[1;32m    553\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n",
       "\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n",
       "\u001B[1;32m    555\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    556\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    557\u001B[0m ):\n",
       "\u001B[0;32m--> 558\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n",
       "\u001B[1;32m    559\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n",
       "\u001B[1;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
       "\u001B[0;32m--> 191\u001B[0m params \u001B[38;5;241m=\u001B[39m func_sig\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    192\u001B[0m params\u001B[38;5;241m.\u001B[39mapply_defaults()\n",
       "\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# ignore self/cls and positional/keyword markers\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3242\u001B[0m, in \u001B[0;36mSignature.bind\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   3237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbind\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m/\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n",
       "\u001B[1;32m   3238\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001B[39;00m\n",
       "\u001B[1;32m   3239\u001B[0m \u001B[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001B[39;00m\n",
       "\u001B[1;32m   3240\u001B[0m \u001B[38;5;124;03m    if the passed arguments can not be bound.\u001B[39;00m\n",
       "\u001B[1;32m   3241\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 3242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bind(args, kwargs)\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3157\u001B[0m, in \u001B[0;36mSignature._bind\u001B[0;34m(self, args, kwargs, partial)\u001B[0m\n",
       "\u001B[1;32m   3155\u001B[0m                 msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmissing a required\u001B[39m\u001B[38;5;132;01m{argtype}\u001B[39;00m\u001B[38;5;124m argument: \u001B[39m\u001B[38;5;132;01m{arg!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n",
       "\u001B[1;32m   3156\u001B[0m                 msg \u001B[38;5;241m=\u001B[39m msg\u001B[38;5;241m.\u001B[39mformat(arg\u001B[38;5;241m=\u001B[39mparam\u001B[38;5;241m.\u001B[39mname, argtype\u001B[38;5;241m=\u001B[39margtype)\n",
       "\u001B[0;32m-> 3157\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   3158\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   3159\u001B[0m     \u001B[38;5;66;03m# We have a positional argument to process\u001B[39;00m\n",
       "\u001B[1;32m   3160\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: missing a required argument: 'y_score'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "TypeError",
        "evalue": "missing a required argument: 'y_score'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: missing a required argument: 'y_score'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-4402110491910889>, line 18\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan\n\u001B[1;32m     17\u001B[0m ndcg_at_2 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\n\u001B[0;32m---> 18\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m: documents_with_relevance_df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext.span_id\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mapply(_compute_ndcg, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)}\n\u001B[1;32m     19\u001B[0m )\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1588\u001B[0m, in \u001B[0;36mGroupBy.apply\u001B[0;34m(self, func, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1580\u001B[0m             new_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1581\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe operation \u001B[39m\u001B[38;5;132;01m{\u001B[39;00morig_func\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m failed on a column. If any error \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1582\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis raised, this will raise an exception in a future version \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1583\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof pandas. Drop these columns to avoid this warning.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1584\u001B[0m             )\n\u001B[1;32m   1585\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m rewrite_warning(\n\u001B[1;32m   1586\u001B[0m                 old_msg, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, new_msg\n\u001B[1;32m   1587\u001B[0m             ) \u001B[38;5;28;01mif\u001B[39;00m is_np_func \u001B[38;5;28;01melse\u001B[39;00m nullcontext():\n\u001B[0;32m-> 1588\u001B[0m                 \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_python_apply_general(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selected_obj)\n\u001B[1;32m   1590\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1629\u001B[0m, in \u001B[0;36mGroupBy._python_apply_general\u001B[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001B[0m\n\u001B[1;32m   1592\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[1;32m   1593\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_python_apply_general\u001B[39m(\n\u001B[1;32m   1594\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1599\u001B[0m     is_agg: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   1600\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NDFrameT:\n\u001B[1;32m   1601\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1602\u001B[0m \u001B[38;5;124;03m    Apply function f in python space\u001B[39;00m\n\u001B[1;32m   1603\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1627\u001B[0m \u001B[38;5;124;03m        data after applying f\u001B[39;00m\n\u001B[1;32m   1628\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1629\u001B[0m     values, mutated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrouper\u001B[38;5;241m.\u001B[39mapply(f, data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis)\n\u001B[1;32m   1630\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m not_indexed_same \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1631\u001B[0m         not_indexed_same \u001B[38;5;241m=\u001B[39m mutated \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmutated\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/ops.py:839\u001B[0m, in \u001B[0;36mBaseGrouper.apply\u001B[0;34m(self, f, data, axis)\u001B[0m\n\u001B[1;32m    837\u001B[0m \u001B[38;5;66;03m# group might be modified\u001B[39;00m\n\u001B[1;32m    838\u001B[0m group_axes \u001B[38;5;241m=\u001B[39m group\u001B[38;5;241m.\u001B[39maxes\n\u001B[0;32m--> 839\u001B[0m res \u001B[38;5;241m=\u001B[39m f(group)\n\u001B[1;32m    840\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mutated \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_indexed_like(res, group_axes, axis):\n\u001B[1;32m    841\u001B[0m     mutated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1540\u001B[0m, in \u001B[0;36mGroupBy.apply.<locals>.f\u001B[0;34m(g)\u001B[0m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf\u001B[39m(g):\n\u001B[1;32m   1539\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1540\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(g, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
        "File \u001B[0;32m<command-4402110491910889>, line 12\u001B[0m, in \u001B[0;36m_compute_ndcg\u001B[0;34m(df, k)\u001B[0m\n\u001B[1;32m     10\u001B[0m eval_scores[: \u001B[38;5;28mlen\u001B[39m(df)] \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39meval_score\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ndcg_score([eval_scores], k\u001B[38;5;241m=\u001B[39mk)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:580\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    578\u001B[0m     patch_function\u001B[38;5;241m.\u001B[39mcall(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 580\u001B[0m     patch_function(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    582\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    584\u001B[0m try_log_autologging_event(\n\u001B[1;32m    585\u001B[0m     AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_patch_function_success,\n\u001B[1;32m    586\u001B[0m     session,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    590\u001B[0m     kwargs,\n\u001B[1;32m    591\u001B[0m )\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/sklearn/__init__.py:1718\u001B[0m, in \u001B[0;36m_autolog.<locals>.patched_metric_api\u001B[0;34m(original, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1714\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mshould_log_post_training_metrics():\n\u001B[1;32m   1715\u001B[0m     \u001B[38;5;66;03m# one metric api may call another metric api,\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m     \u001B[38;5;66;03m# to avoid this, call disable_log_post_training_metrics to avoid nested patch\u001B[39;00m\n\u001B[1;32m   1717\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mdisable_log_post_training_metrics():\n\u001B[0;32m-> 1718\u001B[0m         metric \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1720\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mis_metric_value_loggable(metric):\n\u001B[1;32m   1721\u001B[0m         metric_name \u001B[38;5;241m=\u001B[39m original\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:561\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n\u001B[1;32m    558\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    559\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n\u001B[0;32m--> 561\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:496\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    488\u001B[0m     try_log_autologging_event(\n\u001B[1;32m    489\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_start,\n\u001B[1;32m    490\u001B[0m         session,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    494\u001B[0m         og_kwargs,\n\u001B[1;32m    495\u001B[0m     )\n\u001B[0;32m--> 496\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m original_fn(\u001B[38;5;241m*\u001B[39mog_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mog_kwargs)\n\u001B[1;32m    498\u001B[0m     try_log_autologging_event(\n\u001B[1;32m    499\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_success,\n\u001B[1;32m    500\u001B[0m         session,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    504\u001B[0m         og_kwargs,\n\u001B[1;32m    505\u001B[0m     )\n\u001B[1;32m    506\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:558\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n\u001B[1;32m    550\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n\u001B[1;32m    552\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n\u001B[1;32m    553\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001B[1;32m    555\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    556\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    557\u001B[0m ):\n\u001B[0;32m--> 558\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    559\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n\u001B[0;32m--> 191\u001B[0m params \u001B[38;5;241m=\u001B[39m func_sig\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    192\u001B[0m params\u001B[38;5;241m.\u001B[39mapply_defaults()\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# ignore self/cls and positional/keyword markers\u001B[39;00m\n",
        "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3242\u001B[0m, in \u001B[0;36mSignature.bind\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbind\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m/\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   3238\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001B[39;00m\n\u001B[1;32m   3239\u001B[0m \u001B[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001B[39;00m\n\u001B[1;32m   3240\u001B[0m \u001B[38;5;124;03m    if the passed arguments can not be bound.\u001B[39;00m\n\u001B[1;32m   3241\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bind(args, kwargs)\n",
        "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3157\u001B[0m, in \u001B[0;36mSignature._bind\u001B[0;34m(self, args, kwargs, partial)\u001B[0m\n\u001B[1;32m   3155\u001B[0m                 msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmissing a required\u001B[39m\u001B[38;5;132;01m{argtype}\u001B[39;00m\u001B[38;5;124m argument: \u001B[39m\u001B[38;5;132;01m{arg!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   3156\u001B[0m                 msg \u001B[38;5;241m=\u001B[39m msg\u001B[38;5;241m.\u001B[39mformat(arg\u001B[38;5;241m=\u001B[39mparam\u001B[38;5;241m.\u001B[39mname, argtype\u001B[38;5;241m=\u001B[39margtype)\n\u001B[0;32m-> 3157\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   3158\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3159\u001B[0m     \u001B[38;5;66;03m# We have a positional argument to process\u001B[39;00m\n\u001B[1;32m   3160\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
        "\u001B[0;31mTypeError\u001B[0m: missing a required argument: 'y_score'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "\n",
    "def _compute_ndcg(df: pd.DataFrame, k: int):\n",
    "    \"\"\"Compute NDCG@k in the presence of missing values\"\"\"\n",
    "    n = max(2, len(df))\n",
    "    eval_scores = np.zeros(n)\n",
    "    doc_scores = np.zeros(n)\n",
    "    eval_scores[: len(df)] = df.eval_score\n",
    "    try:\n",
    "        return ndcg_score([eval_scores], k=k)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "ndcg_at_2 = pd.DataFrame(\n",
    "    {\"score\": documents_with_relevance_df.groupby(\"context.span_id\").apply(_compute_ndcg, k=2)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5cb9d46-6952-4b1b-8865-ec580e082dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "precision_at_2 = pd.DataFrame(\n",
    "    {\n",
    "        \"score\": documents_with_relevance_df.groupby(\"context.span_id\").apply(\n",
    "            lambda x: x.eval_score[:2].sum(skipna=False) / 2\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff64b993-43fe-4c73-8a8c-e1fcca003e24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00b0644a6aa222f6</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02eae8211d552185</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>065a5b74f19a8ee0</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011046270e48ea3</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1af0005417e552dd</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259fbec7e399107</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a3d53e0de65c32e</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2c055f2dee5930a2</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2f3bdaccf2465649</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3613029ba02c1609</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4d79bb20dc3469a9</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4ffb3bb2e4365888</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5eb06339668ecba0</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64f5b91d48ca174c</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6cf6fa5fb11e1463</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8bad55aaf70dd076</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8db577a3bc7bd100</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950905a084b6365b</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a132d3de98b25f30</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b7215a8991a374e3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb0f140d9842f83e</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bf77bc6248c21d00</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1bc0ee3b32d457d</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca5cd879bb551cbd</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd3b21c2c361bc5a</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e23a309a889e6b5e</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e3efa64c7c7df34a</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5663c2bbed4a27c</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5929f5b8701a90b</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e6e8a53c4fc30767</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7bf3c5935b02fc9</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  score\n",
       "context.span_id        \n",
       "00b0644a6aa222f6    0.5\n",
       "02eae8211d552185    0.5\n",
       "065a5b74f19a8ee0    0.5\n",
       "1011046270e48ea3    0.5\n",
       "1af0005417e552dd    0.5\n",
       "2259fbec7e399107    0.5\n",
       "2a3d53e0de65c32e    0.5\n",
       "2c055f2dee5930a2    0.5\n",
       "2f3bdaccf2465649    1.0\n",
       "3613029ba02c1609    1.0\n",
       "4d79bb20dc3469a9    1.0\n",
       "4ffb3bb2e4365888    1.0\n",
       "5eb06339668ecba0    0.5\n",
       "64f5b91d48ca174c    0.5\n",
       "6cf6fa5fb11e1463    0.5\n",
       "8bad55aaf70dd076    1.0\n",
       "8db577a3bc7bd100    1.0\n",
       "950905a084b6365b    0.5\n",
       "a132d3de98b25f30    1.0\n",
       "b7215a8991a374e3    1.0\n",
       "bb0f140d9842f83e    1.0\n",
       "bf77bc6248c21d00    0.5\n",
       "c1bc0ee3b32d457d    0.5\n",
       "ca5cd879bb551cbd    1.0\n",
       "cd3b21c2c361bc5a    1.0\n",
       "e23a309a889e6b5e    0.5\n",
       "e3efa64c7c7df34a    0.5\n",
       "e5663c2bbed4a27c    1.0\n",
       "e5929f5b8701a90b    0.5\n",
       "e6e8a53c4fc30767    0.0\n",
       "e7bf3c5935b02fc9    0.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566e750c-aeca-42d3-9817-62a6d0face0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hit = pd.DataFrame(\n",
    "    {\n",
    "        \"hit\": documents_with_relevance_df.groupby(\"context.span_id\").apply(\n",
    "            lambda x: x.eval_score[:2].sum(skipna=False) > 0\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeffcff2-eb89-4382-9e45-03b26b630335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retrievals_df = px.Client().get_spans_dataframe(\n",
    "    \"span_kind == 'RETRIEVER' and input.value is not None\"\n",
    ")\n",
    "rag_evaluation_dataframe = pd.concat(\n",
    "    [\n",
    "        retrievals_df[\"attributes.input.value\"],\n",
    "        precision_at_2.add_prefix(\"precision@2_\"),\n",
    "        hit,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "rag_evaluation_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c3125bb-6226-43b8-a66e-dde995f64b0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "precision@2_score    0.677419\n",
       "hit                  0.967742\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate the scores across the retrievals\n",
    "results = rag_evaluation_dataframe.mean(numeric_only=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b8258b8-d516-4a63-bb6a-c555e998e220",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from phoenix.trace import DocumentEvaluations, SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(dataframe=precision_at_2, eval_name=\"precision@2\"),\n",
    "    DocumentEvaluations(dataframe=retrieved_documents_relevance_df, eval_name=\"relevance\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8829c8fe-9f75-4fda-9e0d-e79e1767c4cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca7aa2a22839c2b7</th>\n",
       "      <td>What information is available in the context?</td>\n",
       "      <td>{\"result\": \"The context provides information about a regulation related to autonomous actions affecting certain systems (Category A systems) in the context of AI. It mentions that operators must maintain comprehensive documentation of decision paths for these autonomous actions. However, it does not provide information about philosophical questions, regulatory compliance across multiple jurisdictions, or impact on market dynamics and competitive positioning.\", \"source_documents\": [\"page_content='. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).' metadata={'_id': '72cd6582f98344139138a689b4c4a13f', '_collection_name': 'my_documents'}\", \"page_content='2. Philosophical questions about AI agency and responsibility\\n3. Regulatory compliance across multiple jurisdictions\\n4. Impact on market dynamics and competitive positioning' metadata={'_id': 'ddef3f0b37484073a21ca25eb25e4c5c', '_collection_name': 'my_documents'}\"]}</td>\n",
       "      <td>. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).\\n\\n2. Philosophical questions about AI agency and responsibility\\n3. Regulatory compliance across multiple jurisdictions\\n4. Impact on market dynamics and competitive positioning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          input  ...                                                                                                                                                                                                                                                                                                                                                                         reference\n",
       "context.span_id                                                  ...                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "ca7aa2a22839c2b7  What information is available in the context?  ...  . Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).\\n\\n2. Philosophical questions about AI agency and responsibility\\n3. Regulatory compliance across multiple jurisdictions\\n4. Impact on market dynamics and competitive positioning\n",
       "\n",
       "[1 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.session.evaluation import get_qa_with_reference\n",
    "\n",
    "qa_with_reference_df = get_qa_with_reference(px.Client())\n",
    "qa_with_reference_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26280a8c-15f9-4640-88f5-05826dfab5f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from phoenix.evals import (\n",
    "    HallucinationEvaluator,\n",
    "    OpenAIModel,\n",
    "    LiteLLMModel,\n",
    "    QAEvaluator,\n",
    "    run_evals,\n",
    ")\n",
    "\n",
    "qa_evaluator = QAEvaluator(LiteLLMModel(\n",
    "    model=\"azure/gpt-35-turbo\"\n",
    "))\n",
    "hallucination_evaluator = HallucinationEvaluator(LiteLLMModel(\n",
    "    model=\"azure/gpt-35-turbo\"\n",
    "))\n",
    "\n",
    "qa_correctness_eval_df, hallucination_eval_df = run_evals(\n",
    "    evaluators=[qa_evaluator, hallucination_evaluator],\n",
    "    dataframe=qa_with_reference_df,\n",
    "    provide_explanation=True,\n",
    "    concurrency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3679cc9d-3958-4a37-9fa2-186442668561",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67450fc84b588cce</th>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "      <td>The answer provided does correctly answer the question. The reference text states that the issue with the physical diploma was that the quotes had been included, making them read as scare-quotes. The answer directly quotes this information and provides the context in which the issue was discovered. Therefore, the answer is \"correct\". \\nLABEL: \"correct\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267f5fb10d21f760</th>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "      <td>The answer correctly states that the issue with the quotes on the physical diploma was that they made the words appear as scare-quotes, which the person found bothersome at the time. This is supported by the reference text, which states \"When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\" Therefore, the answer is correct.\\nLABEL: \"correct\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3e18e69029b958f</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>The question asks for the purpose of launching privately before launching publicly. The reference text states that the purpose was to recruit an initial set of users and ensure they had decent-looking stores. The answer provides two separate quotes from the reference text, one stating the purpose of recruiting an initial set of users and the other stating the benefit of having colleagues who understand the problems faced by founders. While the second quote may be related to the benefits of launching privately, it does not directly answer the question. Therefore, the answer is partially correct but not fully correct. \\nLABEL: \"incorrect\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7ca7b83ec02db4e7</th>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "      <td>The answer correctly states that the purpose of launching privately before launching publicly was to recruit an initial set of users and ensure they had decent-looking stores. Additionally, it correctly identifies that one of the benefits of launching privately was to address the isolation faced by founders by providing colleagues who understood their problems. Therefore, the answer fully and accurately answers the question. \\nLABEL: \"correct\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8f8f3de66bfbb47c</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>The answer does not provide any information about the author's opinion on the painting method described in the context. Therefore, the answer is incorrect. \\nLABEL: \"incorrect\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           explanation\n",
       "context.span_id              ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "67450fc84b588cce    correct  ...                                                                                                                                                                                                                                                                                                    The answer provided does correctly answer the question. The reference text states that the issue with the physical diploma was that the quotes had been included, making them read as scare-quotes. The answer directly quotes this information and provides the context in which the issue was discovered. Therefore, the answer is \"correct\". \\nLABEL: \"correct\"\n",
       "267f5fb10d21f760    correct  ...                                                                                                                    The answer correctly states that the issue with the quotes on the physical diploma was that they made the words appear as scare-quotes, which the person found bothersome at the time. This is supported by the reference text, which states \"When I got the actual physical diploma, I was dismayed to find that the quotes had been included, which made them read as scare-quotes. At the time this bothered me, but now it seems amusingly accurate, for reasons I was about to discover.\" Therefore, the answer is correct.\\nLABEL: \"correct\"\n",
       "b3e18e69029b958f  incorrect  ...  The question asks for the purpose of launching privately before launching publicly. The reference text states that the purpose was to recruit an initial set of users and ensure they had decent-looking stores. The answer provides two separate quotes from the reference text, one stating the purpose of recruiting an initial set of users and the other stating the benefit of having colleagues who understand the problems faced by founders. While the second quote may be related to the benefits of launching privately, it does not directly answer the question. Therefore, the answer is partially correct but not fully correct. \\nLABEL: \"incorrect\"\n",
       "7ca7b83ec02db4e7    correct  ...                                                                                                                                                                                                       The answer correctly states that the purpose of launching privately before launching publicly was to recruit an initial set of users and ensure they had decent-looking stores. Additionally, it correctly identifies that one of the benefits of launching privately was to address the isolation faced by founders by providing colleagues who understood their problems. Therefore, the answer fully and accurately answers the question. \\nLABEL: \"correct\"\n",
       "8f8f3de66bfbb47c  incorrect  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The answer does not provide any information about the author's opinion on the painting method described in the context. Therefore, the answer is incorrect. \\nLABEL: \"incorrect\"\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_correctness_eval_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a48a38a5-2d87-4144-867c-4e4e2ce79d6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67450fc84b588cce</th>\n",
       "      <td>hallucinated</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The answer provided does not address the query of \"What was the issue with the quotes on the physical diploma?\" and instead provides two separate sentences from the reference text. Therefore, the answer is hallucinated. \\nLABEL: hallucinated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267f5fb10d21f760</th>\n",
       "      <td>factual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The answer correctly states that the issue with the quotes on the physical diploma was that they made the words appear as scare-quotes, which the person found bothersome at the time. This information is directly stated in the reference text. Therefore, the answer is factual. \\n\\nLABEL: factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3e18e69029b958f</th>\n",
       "      <td>factual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The answer provided contains two parts of the reference text that directly answer the query. The first part explains that the purpose of launching privately was to recruit an initial set of users and ensure they had decent-looking stores before launching publicly. The second part explains that launching privately also solved the problem of isolation for founders by providing colleagues who understood the problems they were facing. Therefore, the answer is factual and provides accurate information based on the reference text. \\n\\nLABEL: factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7ca7b83ec02db4e7</th>\n",
       "      <td>factual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The answer accurately reflects the information provided in the reference text. It states that the purpose of launching privately before launching publicly was to recruit an initial set of users, ensure they had decent-looking stores, and address the isolation faced by founders by providing colleagues who understood their problems. This information is supported by the reference text, which states that the company had to launch privately to recruit an initial set of users and ensure they had decent-looking stores, and that launching privately also addressed the isolation faced by founders by providing colleagues who understood their problems. Therefore, the answer is factual. \\nLABEL: factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8f8f3de66bfbb47c</th>\n",
       "      <td>hallucinated</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The query asks for the author's opinion on the painting method described in the context. The reference text mentions painting and painting students, but does not provide any specific information about a painting method or the author's opinion on it. The answer provided is a set of two documents that do not directly address the query or provide any information about the author's opinion on a painting method. Therefore, the answer is hallucinated as it does not provide factual information related to the query and reference text. \\n\\nLABEL: hallucinated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         label  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  explanation\n",
       "context.span_id                 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "67450fc84b588cce  hallucinated  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                            The answer provided does not address the query of \"What was the issue with the quotes on the physical diploma?\" and instead provides two separate sentences from the reference text. Therefore, the answer is hallucinated. \\nLABEL: hallucinated\n",
       "267f5fb10d21f760       factual  ...                                                                                                                                                                                                                                                                                                                                                                                                                       The answer correctly states that the issue with the quotes on the physical diploma was that they made the words appear as scare-quotes, which the person found bothersome at the time. This information is directly stated in the reference text. Therefore, the answer is factual. \\n\\nLABEL: factual\n",
       "b3e18e69029b958f       factual  ...                                                                                                                                                        The answer provided contains two parts of the reference text that directly answer the query. The first part explains that the purpose of launching privately was to recruit an initial set of users and ensure they had decent-looking stores before launching publicly. The second part explains that launching privately also solved the problem of isolation for founders by providing colleagues who understood the problems they were facing. Therefore, the answer is factual and provides accurate information based on the reference text. \\n\\nLABEL: factual\n",
       "7ca7b83ec02db4e7       factual  ...  The answer accurately reflects the information provided in the reference text. It states that the purpose of launching privately before launching publicly was to recruit an initial set of users, ensure they had decent-looking stores, and address the isolation faced by founders by providing colleagues who understood their problems. This information is supported by the reference text, which states that the company had to launch privately to recruit an initial set of users and ensure they had decent-looking stores, and that launching privately also addressed the isolation faced by founders by providing colleagues who understood their problems. Therefore, the answer is factual. \\nLABEL: factual\n",
       "8f8f3de66bfbb47c  hallucinated  ...                                                                                                                                                 The query asks for the author's opinion on the painting method described in the context. The reference text mentions painting and painting students, but does not provide any specific information about a painting method or the author's opinion on it. The answer provided is a set of two documents that do not directly address the query or provide any information about the author's opinion on a painting method. Therefore, the answer is hallucinated as it does not provide factual information related to the query and reference text. \\n\\nLABEL: hallucinated\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_eval_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "319378ae-1622-41e0-acd7-42176999c777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "score    0.733333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_correctness_eval_df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f495b0d6-2a61-4ef7-b1be-4bd920bd41e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "score    0.233333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_eval_df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7017b47e-5ec6-46d3-b437-13fa294b2ebf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(dataframe=qa_correctness_eval_df, eval_name=\"Q&A Correctness\"),\n",
    "    SpanEvaluations(dataframe=hallucination_eval_df, eval_name=\"Hallucination\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Phoenix eval",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
