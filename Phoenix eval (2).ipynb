{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd3f1b50-ab3e-4f68-9cec-4e0d397d4c00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatabricks-feature-engineering 0.7.0 requires protobuf<5,>=3.12.0, but you have protobuf 5.29.1 which is incompatible.\nmlflow-skinny 2.15.1 requires importlib-metadata!=4.7.0,<8,>=3.7.0, but you have importlib-metadata 8.4.0 which is incompatible.\ntensorboard-plugin-profile 2.17.0 requires protobuf<5.0.0dev,>=3.19.6, but you have protobuf 5.29.1 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0m\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq \"protobuf>=4.21.6\"  qdrant-client tiktoken \"arize-phoenix[evals,embeddings]\" \"openai>=1\" openinference-instrumentation-langchain litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28597f08-ac19-4fed-bafe-61d4361faa90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain<0.4.0,>=0.1.0 in /databricks/python3/lib/python3.12/site-packages (0.2.12)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.1.0) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /databricks/python3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.1.0) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /databricks/python3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.1.0) (3.9.5)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /databricks/python3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.1.0) (0.2.41)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /databricks/python3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.1.0) (0.2.4)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /databricks/python3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.1.0) (0.1.133)\nRequirement already satisfied: numpy<2.0.0,>=1.26.0 in /databricks/python3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.1.0) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.1.0) (2.8.2)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.1.0) (2.32.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.1.0) (8.2.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.1.0) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.1.0) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.1.0) (1.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.1.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.1.0) (1.9.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain<0.4.0,>=0.1.0) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain<0.4.0,>=0.1.0) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain<0.4.0,>=0.1.0) (4.11.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.1.0) (0.27.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.1.0) (3.10.7)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.1.0) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.4.0,>=0.1.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.4.0,>=0.1.0) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.1.0) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.1.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.1.0) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.1.0) (2024.6.2)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.1.0) (3.0.1)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.1.0) (4.2.0)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.1.0) (1.0.6)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.1.0) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.1.0) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain<0.4.0,>=0.1.0) (3.0.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: langchain-core<0.4.0,>=0.1.0 in /databricks/python3/lib/python3.12/site-packages (0.2.41)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.1.0) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.1.0) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.112 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.1.0) (0.1.133)\nRequirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.1.0) (24.1)\nRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.1.0) (2.8.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.1.0) (8.2.2)\nRequirement already satisfied: typing-extensions>=4.7 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.1.0) (4.11.0)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.1.0) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (0.27.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (3.10.7)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (2.32.2)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.4.0,>=0.1.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.4.0,>=0.1.0) (2.20.1)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (4.2.0)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (1.0.6)\nRequirement already satisfied: idna in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (3.7)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (0.14.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.4.0,>=0.1.0) (1.26.16)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting langchain-openai>=0.0.2\n  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\nCollecting langchain-core<0.4.0,>=0.3.21 (from langchain-openai>=0.0.2)\n  Downloading langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: openai<2.0.0,>=1.55.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from langchain-openai>=0.0.2) (1.57.2)\nRequirement already satisfied: tiktoken<1,>=0.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from langchain-openai>=0.0.2) (0.8.0)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (1.33)\nRequirement already satisfied: langsmith<0.3,>=0.1.125 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (0.1.133)\nRequirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (24.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (2.8.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (8.2.2)\nRequirement already satisfied: typing-extensions>=4.7 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (4.11.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.12/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai>=0.0.2) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai>=0.0.2) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.12/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai>=0.0.2) (0.27.2)\nRequirement already satisfied: jiter<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai>=0.0.2) (0.6.1)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai>=0.0.2) (1.3.0)\nRequirement already satisfied: tqdm>4 in /databricks/python3/lib/python3.12/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai>=0.0.2) (4.66.4)\nRequirement already satisfied: regex>=2022.1.18 in /databricks/python3/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.0.2) (2023.10.3)\nRequirement already satisfied: requests>=2.26.0 in /databricks/python3/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.0.2) (2.32.2)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai>=0.0.2) (3.7)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai>=0.0.2) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai>=0.0.2) (1.0.6)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai>=0.0.2) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (3.10.7)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain-openai>=0.0.2) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai>=0.0.2) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai>=0.0.2) (1.26.16)\nDownloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/50.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m50.7/50.7 kB\u001B[0m \u001B[31m7.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading langchain_core-0.3.24-py3-none-any.whl (410 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/410.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 kB\u001B[0m \u001B[31m61.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: langchain-core, langchain-openai\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.2.41\n    Not uninstalling langchain-core at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a\n    Can't uninstall 'langchain-core'. No files were found to uninstall.\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain 0.2.12 requires langchain-core<0.3.0,>=0.2.27, but you have langchain-core 0.3.24 which is incompatible.\nlangchain-text-splitters 0.2.4 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.24 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed langchain-core-0.3.24 langchain-openai-0.2.12\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting langchain-community>=0.0.10\n  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.12/site-packages (from langchain-community>=0.0.10) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /databricks/python3/lib/python3.12/site-packages (from langchain-community>=0.0.10) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /databricks/python3/lib/python3.12/site-packages (from langchain-community>=0.0.10) (3.9.5)\nCollecting dataclasses-json<0.7,>=0.5.7 (from langchain-community>=0.0.10)\n  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\nCollecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community>=0.0.10)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langchain<0.4.0,>=0.3.11 (from langchain-community>=0.0.10)\n  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from langchain-community>=0.0.10) (0.3.24)\nRequirement already satisfied: langsmith<0.3,>=0.1.125 in /databricks/python3/lib/python3.12/site-packages (from langchain-community>=0.0.10) (0.1.133)\nRequirement already satisfied: numpy<3,>=1.26.2 in /databricks/python3/lib/python3.12/site-packages (from langchain-community>=0.0.10) (1.26.4)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community>=0.0.10)\n  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.12/site-packages (from langchain-community>=0.0.10) (2.32.2)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-community>=0.0.10) (8.2.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.10) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.10) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.10) (1.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.10) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.10) (1.9.3)\nCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.0.10)\n  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\nCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.0.10)\n  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.11->langchain-community>=0.0.10)\n  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /databricks/python3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.11->langchain-community>=0.0.10) (2.8.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community>=0.0.10) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community>=0.0.10) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community>=0.0.10) (4.11.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-community>=0.0.10) (0.27.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-community>=0.0.10) (3.10.7)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-community>=0.0.10) (1.0.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community>=0.0.10) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.0.10) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.0.10) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.0.10) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community>=0.0.10) (2024.6.2)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community>=0.0.10) (3.0.1)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community>=0.0.10) (4.2.0)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community>=0.0.10) (1.0.6)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community>=0.0.10) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community>=0.0.10) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain-community>=0.0.10) (3.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community>=0.0.10) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community>=0.0.10) (2.20.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community>=0.0.10) (1.0.0)\nDownloading langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m159.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\nDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain-0.3.11-py3-none-any.whl (1.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m240.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\nDownloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\nDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/49.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.5/49.5 kB\u001B[0m \u001B[31m210.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nInstalling collected packages: typing-inspect, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-text-splitters, langchain, langchain-community\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.2.4\n    Not uninstalling langchain-text-splitters at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a\n    Can't uninstall 'langchain-text-splitters'. No files were found to uninstall.\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.2.12\n    Not uninstalling langchain at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a\n    Can't uninstall 'langchain'. No files were found to uninstall.\nSuccessfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.11 langchain-community-0.3.11 langchain-text-splitters-0.3.2 marshmallow-3.23.1 pydantic-settings-2.6.1 typing-inspect-0.9.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting langchain-groq>=0.2.0\n  Downloading langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting groq<1,>=0.4.1 (from langchain-groq>=0.2.0)\n  Downloading groq-0.13.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from langchain-groq>=0.2.0) (0.3.24)\nRequirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.12/site-packages (from groq<1,>=0.4.1->langchain-groq>=0.2.0) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq>=0.2.0) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.12/site-packages (from groq<1,>=0.4.1->langchain-groq>=0.2.0) (0.27.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from groq<1,>=0.4.1->langchain-groq>=0.2.0) (2.8.2)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from groq<1,>=0.4.1->langchain-groq>=0.2.0) (1.3.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /databricks/python3/lib/python3.12/site-packages (from groq<1,>=0.4.1->langchain-groq>=0.2.0) (4.11.0)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq>=0.2.0) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq>=0.2.0) (1.33)\nRequirement already satisfied: langsmith<0.3,>=0.1.125 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq>=0.2.0) (0.1.133)\nRequirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq>=0.2.0) (24.1)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq>=0.2.0) (8.2.2)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq>=0.2.0) (3.7)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq>=0.2.0) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq>=0.2.0) (1.0.6)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq>=0.2.0) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-groq>=0.2.0) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq>=0.2.0) (3.10.7)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq>=0.2.0) (2.32.2)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq>=0.2.0) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq>=0.2.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq>=0.2.0) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq>=0.2.0) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq>=0.2.0) (1.26.16)\nDownloading langchain_groq-0.2.1-py3-none-any.whl (14 kB)\nDownloading groq-0.13.0-py3-none-any.whl (108 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/108.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m108.8/108.8 kB\u001B[0m \u001B[31m12.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: groq, langchain-groq\nSuccessfully installed groq-0.13.0 langchain-groq-0.2.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: langchain-text-splitters>=0.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (0.3.2)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from langchain-text-splitters>=0.0.1) (0.3.24)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (1.33)\nRequirement already satisfied: langsmith<0.3,>=0.1.125 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (0.1.133)\nRequirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (24.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (2.8.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (8.2.2)\nRequirement already satisfied: typing-extensions>=4.7 in /databricks/python3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (4.11.0)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (0.27.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (3.10.7)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (2.32.2)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (2.20.1)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (4.2.0)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (1.0.6)\nRequirement already satisfied: idna in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (3.7)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (0.14.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters>=0.0.1) (1.26.16)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: openinference-instrumentation-langchain>=0.1.29 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (0.1.29)\nRequirement already satisfied: openinference-instrumentation>=0.1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from openinference-instrumentation-langchain>=0.1.29) (0.1.19)\nRequirement already satisfied: openinference-semantic-conventions>=0.1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from openinference-instrumentation-langchain>=0.1.29) (0.1.12)\nRequirement already satisfied: opentelemetry-api in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from openinference-instrumentation-langchain>=0.1.29) (1.28.2)\nRequirement already satisfied: opentelemetry-instrumentation in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from openinference-instrumentation-langchain>=0.1.29) (0.49b2)\nRequirement already satisfied: opentelemetry-semantic-conventions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from openinference-instrumentation-langchain>=0.1.29) (0.49b2)\nRequirement already satisfied: wrapt in /databricks/python3/lib/python3.12/site-packages (from openinference-instrumentation-langchain>=0.1.29) (1.14.1)\nRequirement already satisfied: opentelemetry-sdk in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from openinference-instrumentation>=0.1.17->openinference-instrumentation-langchain>=0.1.29) (1.28.2)\nRequirement already satisfied: deprecated>=1.2.6 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-api->openinference-instrumentation-langchain>=0.1.29) (1.2.14)\nRequirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages (from opentelemetry-api->openinference-instrumentation-langchain>=0.1.29) (8.4.0)\nRequirement already satisfied: packaging>=18.0 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-instrumentation->openinference-instrumentation-langchain>=0.1.29) (24.1)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api->openinference-instrumentation-langchain>=0.1.29) (3.17.0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-sdk->openinference-instrumentation>=0.1.17->openinference-instrumentation-langchain>=0.1.29) (4.11.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mWarning: statements after `dbutils.library.restartPython()` will execute before Python is restarted.\u001B[0m\nlangchain==0.3.11\nlangchain-community==0.3.11\nlangchain-core==0.3.24\nlangchain-groq==0.2.1\nlangchain-openai==0.2.12\nlangchain-text-splitters==0.3.2\nopeninference-instrumentation-langchain==0.1.29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %pip uninstall -y langchain langchain-core langchain-openai langchain-community langchain-groq langchain-text-splitters openinference-instrumentation-langchain\n",
    "\n",
    "%pip install --no-cache-dir \"langchain>=0.1.0,<0.4.0\"\n",
    "%pip install --no-cache-dir \"langchain-core>=0.1.0,<0.4.0\"\n",
    "%pip install --no-cache-dir \"langchain-openai>=0.0.2\"\n",
    "%pip install --no-cache-dir \"langchain-community>=0.0.10\"\n",
    "%pip install --no-cache-dir \"langchain-groq>=0.2.0\"\n",
    "%pip install --no-cache-dir \"langchain-text-splitters>=0.0.1\"\n",
    "%pip install --no-cache-dir \"openinference-instrumentation-langchain>=0.1.29\"\n",
    "\n",
    "dbutils.library.restartPython()\n",
    "\n",
    "# Verify installations (run after restart)\n",
    "%pip freeze | grep langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29b8992f-4178-4e5a-95ea-75cfb2c8daf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceda49ce-bec8-4135-bab2-933978ee03ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain: 0.3.11\nlangchain-community: 0.3.11\nlangchain-core: 0.3.24\nlangchain-groq: 0.2.1\nlangchain-openai: 0.2.12\nlangchain-text-splitters: 0.3.2\nopeninference-instrumentation-langchain: 0.1.29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages.ai import InputTokenDetails\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "# Print package versions to verify\n",
    "import pkg_resources\n",
    "packages = [\n",
    "    'langchain',\n",
    "    'langchain-community',\n",
    "    'langchain-core',\n",
    "    'langchain-groq',\n",
    "    'langchain-openai',\n",
    "    'langchain-text-splitters',\n",
    "    'openinference-instrumentation-langchain'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(package).version\n",
    "        print(f\"{package}: {version}\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"{package}: Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "182c5a58-c857-4926-97a0-3b05cd0d1ce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "from getpass import getpass\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "\n",
    "import phoenix as px\n",
    "from phoenix.otel import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b52df3d-75f7-4350-a5f9-7d227dfea7ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "px.close_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d8f52ec-ac5d-4b6e-ad88-284a8995b197",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/75992/command-4402110491910851-2227220095:20: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n  embeddings = OpenAIEmbeddings(\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages/langchain_community/embeddings/openai.py:271: UserWarning: WARNING! api_type is not default parameter.\n                    api_type was transferred to model_kwargs.\n                    Please confirm that api_type is what you intended.\n  warnings.warn(\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-7e5cbdd1-3a45-49c3-887c-69c57584de4a/lib/python3.12/site-packages/langchain_community/embeddings/openai.py:271: UserWarning: WARNING! api_base is not default parameter.\n                    api_base was transferred to model_kwargs.\n                    Please confirm that api_base is what you intended.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Initialization\n",
    "nest_asyncio.apply()\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Configure Groq API Key using dbutils\n",
    "try:\n",
    "    groq_api_key = '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'\n",
    "    os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
    "    os.environ[\"PHOENIX_PROJECT_NAME\"] = \"Phoenix_Capabilities_Testing\"\n",
    "    os.environ[\"AZURE_API_KEY\"] = \"38a6b22e0e4f43828877d844399faf4d\"\n",
    "    os.environ[\"AZURE_API_BASE\"] = \"https://ai-abhinavkatiyarai793972137108.openai.azure.com\" \n",
    "    os.environ[\"AZURE_API_VERSION\"] = \"2024-08-01-preview\"\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error accessing Groq API key from secrets. Please add it to the 'llm-keys' scope with key 'groq-api-key'\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "# Configure Azure OpenAI Embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    deployment=\"text-embedding-ada-002\",  # Your Azure OpenAI deployment name\n",
    "    model=\"text-embedding-ada-002\",      # OpenAI model name\n",
    "    api_type=\"azure\",\n",
    "    api_base=\"https://abhin-m2ifqtz5-eastus2.openai.azure.com\",  # Azure OpenAI endpoint\n",
    "    api_version=\"2023-05-15\",    # Azure API version for embeddings\n",
    "    api_key=\"4f46e8f30eac4a3abedeb41c04b7ab52\"  # Azure OpenAI API key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15e9bd4d-5772-4e94-a707-079066909699",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/75992/command-4402110491910852-2342295847:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  embeddings = HuggingFaceEmbeddings(\n2024-12-11 05:28:13.650251: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2024-12-11 05:28:13.777212: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2024-12-11 05:28:13.901957: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1733894894.012709   75992 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1733894894.046731   75992 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-12-11 05:28:14.482329: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n/databricks/python/lib/python3.12/site-packages/sentence_transformers/evaluation/SentenceEvaluator.py:81: SyntaxWarning: invalid escape sequence '\\g'\n  return re.sub(r\"([a-z])([A-Z])\", \"\\g<1> \\g<2>\", class_name)\n/databricks/python/lib/python3.12/site-packages/sentence_transformers/model_card.py:524: SyntaxWarning: invalid escape sequence '\\d'\n  if dataset_name and re.match(\"_dataset_\\d+\", dataset_name):\n/databricks/python/lib/python3.12/site-packages/sentence_transformers/losses/DenoisingAutoEncoderLoss.py:16: SyntaxWarning: invalid escape sequence '\\_'\n  \"\"\"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3746ff4aa2449ccb6f0c01cc2399874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b0270e8da54d61a3f8917e67aeea32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93536a04daa846f89004f6e480eaf394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a83740cec4e4b1cab9595df94c483da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9699d44fd6ee4b62b3b43ec5602bc195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b1dad5311344f19e8dcd595b80d6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b458823ef77440dc9bea03654712e3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf32cb6321847bb98ab0e570799405f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8140a70326af47d9a0ec4ae720ad2437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3396be58c6054ea489f4d0f3a43f6667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cc717fea9d422e837cd881f7bb4056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure embeddings using SentenceTransformers\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_documents(directory_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.txt'):  \n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            loader = TextLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "documents = load_documents('/Workspace/Users/abhinav.katiyar@spaceinventive.com/data/')\n",
    "\n",
    "# Create text splitter for smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Process documents into chunks\n",
    "all_chunks = []\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    valid_chunks = [chunk for chunk in chunks if len(chunk) > 100]\n",
    "    all_chunks.extend(valid_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "401d12cc-1845-4623-a4a3-3e359ade4b91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 05:28:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/tracing/utils/__init__.py:53: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n\nFor example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\nwith: `from pydantic import BaseModel`\nor the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n\"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-3141e605f5f04ab6a7380fd7477617ca\", \"tr-842751f40b8449d9af07f74b74701c93\"]",
      "text/plain": [
       "[Trace(request_id=tr-3141e605f5f04ab6a7380fd7477617ca), Trace(request_id=tr-842751f40b8449d9af07f74b74701c93)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "# Configure Azure OpenAI embeddings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=\"https://abhin-m2ifqtz5-eastus2.openai.azure.com\",\n",
    "    deployment=\"text-embedding-ada-002\",  # Changed from azure_deployment to deployment\n",
    "    api_key=\"4f46e8f30eac4a3abedeb41c04b7ab52\",\n",
    "    api_version=\"2023-05-15\"\n",
    ")\n",
    "\n",
    "def load_documents(directory_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.txt'):  \n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            loader = TextLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "documents = load_documents('/Workspace/Users/abhinav.katiyar@spaceinventive.com/data/')\n",
    "\n",
    "# Create text splitter for smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Process documents into chunks\n",
    "texts = text_splitter.split_documents(documents)  # Changed to split_documents instead of manual splitting\n",
    "\n",
    "# Build vector store\n",
    "qdrant = Qdrant.from_documents(\n",
    "    texts,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"my_documents\",\n",
    ")\n",
    "\n",
    "# Configure retriever\n",
    "retriever = qdrant.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 2,\n",
    "        \"fetch_k\": 3\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c436b95-baa0-4885-b607-af63e8979359",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-5832e30c82944ab880cdb11d8a31be8f\", \"tr-0e5663eb6c094ac68501ca641ce98192\"]",
      "text/plain": [
       "[Trace(request_id=tr-5832e30c82944ab880cdb11d8a31be8f), Trace(request_id=tr-0e5663eb6c094ac68501ca641ce98192)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Build vector store\n",
    "qdrant = Qdrant.from_documents(\n",
    "    texts,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"my_documents\",\n",
    ")\n",
    "\n",
    "# Configure retriever\n",
    "retriever = qdrant.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 2,\n",
    "        \"fetch_k\": 3\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure Groq for question generation\n",
    "question_llm = ChatGroq(\n",
    "    model_name=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=512,\n",
    "    streaming=False\n",
    ")\n",
    "\n",
    "# Configure Groq for QA\n",
    "qa_llm = ChatGroq(\n",
    "    model_name=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1024,\n",
    "    streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e2a1363-a41b-4b68-8792-ca276bbf4be5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/75992/command-4402110491910854-926698858:45: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  question_chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Question Generation Template\n",
    "# generate_questions_template = \"\"\"Create exactly 3 questions based on this text. Only return a JSON object.\n",
    "\n",
    "# TEXT TO ANALYZE:\n",
    "# {text}\n",
    "\n",
    "# RESPONSE FORMAT:\n",
    "# {{\n",
    "# \"question_1\": \"Write your first question here\",\n",
    "# \"question_2\": \"Write your second question here\",\n",
    "# \"question_3\": \"Write your third question here\"\n",
    "# }}\n",
    "\n",
    "# IMPORTANT: Only return the JSON object, no additional text.\"\"\"\n",
    "\n",
    "generate_questions_template = \"\"\"\\\n",
    "Context information is below.\n",
    "\n",
    "---------------------\n",
    "{text}\n",
    "---------------------\n",
    "\n",
    "Given the context information and not prior knowledge.\n",
    "generate only questions based on the below query.\n",
    "\n",
    "You are a Teacher/ Professor. Your task is to setup \\\n",
    "3 questions for an upcoming \\\n",
    "quiz/examination. The questions should be diverse in nature \\\n",
    "across the document. Restrict the questions to the \\\n",
    "context information provided.\"\n",
    "\n",
    "Output the questions in JSON format with the keys question_1, question_2, question_3.\n",
    "\"\"\"\n",
    "\n",
    "# QA Template\n",
    "qa_prompt_template = \"\"\"Answer the following question based on the given context. Be concise.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "# Create chains\n",
    "question_chain = LLMChain(\n",
    "    llm=question_llm,\n",
    "    prompt=PromptTemplate(\n",
    "        template=generate_questions_template,\n",
    "        input_variables=[\"text\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=qa_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": PromptTemplate(\n",
    "            template=qa_prompt_template,\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e99d572f-6ac3-4808-81e9-59d6cc37feb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<phoenix.session.session.ThreadSession object at 0x7f09dfee7d40>\n"
     ]
    }
   ],
   "source": [
    "session = px.active_session()\n",
    "print(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "643a6e00-c28b-4929-b184-d6b2fa869a06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0.1\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "print(px.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d8bc68b-283b-4c53-abf6-0d5edcf1389b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-159938735837198>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m session \u001B[38;5;241m=\u001B[39m px\u001B[38;5;241m.\u001B[39mSession(endpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp://localhost:6006\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: Can't instantiate abstract class Session without an implementation for abstract methods 'active', 'end'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "TypeError",
        "evalue": "Can't instantiate abstract class Session without an implementation for abstract methods 'active', 'end'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: Can't instantiate abstract class Session without an implementation for abstract methods 'active', 'end'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-159938735837198>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m session \u001B[38;5;241m=\u001B[39m px\u001B[38;5;241m.\u001B[39mSession(endpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp://localhost:6006\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "\u001B[0;31mTypeError\u001B[0m: Can't instantiate abstract class Session without an implementation for abstract methods 'active', 'end'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "session = px.Session(endpoint=\"http://localhost:6006\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e318aefa-b642-4f26-8247-c97fca837489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔭 OpenTelemetry Tracing Details 🔭\n|  Phoenix Project: Phoenix_Capabilities_Testing\n|  Span Processor: SimpleSpanProcessor\n|  Collector Endpoint: localhost:4317\n|  Transport: gRPC\n|  Transport Headers: {'user-agent': '****'}\n|  \n|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n|  \n|  `register` has set this TracerProvider as the global OpenTelemetry default.\n|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n\n🌍 To view the Phoenix app in your browser, visit https://adb-182495964472138.18.azuredatabricks.net/driver-proxy/o/182495964472138/1205-082119-n66oclg8/6006/\n📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\nPhoenix UI available at: https://adb-182495964472138.18.azuredatabricks.net/driver-proxy/o/182495964472138/1205-082119-n66oclg8/6006/\n"
     ]
    }
   ],
   "source": [
    "tracer_provider = register()\n",
    "LangChainInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)\n",
    "\n",
    "# Launch Phoenix\n",
    "session = px.launch_app()\n",
    "print(f\"Phoenix UI available at: {session.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f70c4b71-0f74-49ce-b57b-37f89d51ebe9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 05:29:28 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:558: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What information is available in the context?\nThe context provides information about the variation in the burden of proof for establishing causation in hybrid human-AI decision chains across different jurisdictions. It also mentions a business case study related to GlobalTech's market position, but no specific details or information about this case are given.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-317ef45af04047c5bef3755ca10fd948\"",
      "text/plain": [
       "Trace(request_id=tr-317ef45af04047c5bef3755ca10fd948)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"What information is available in the context?\"\n",
    "\n",
    "response = qa_chain({\"query\": question})\n",
    "print(response['query'])\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "926fc824-ad7a-4682-b8fc-5f785242d5d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>span_kind</th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>attributes.retrieval.documents</th>\n",
       "      <th>attributes.llm.output_messages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ebed2652caff587f</th>\n",
       "      <td>VectorStoreRetriever</td>\n",
       "      <td>RETRIEVER</td>\n",
       "      <td>What information is available in the context?</td>\n",
       "      <td>[{'document.content': '. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).', 'document.metadata': {'_id': '7521ad8bff3940d18234c357bc85e5c2', '_collection_name': 'my_documents'}}, {'document.content': '2. Philosophical questions about AI agency and responsibility\n",
       "3. Regulatory compliance across multiple jurisdictions\n",
       "4. Impact on market dynamics and competitive positioning', 'document.metadata': {'_id': 'e45ea86acad148c1b62af39cec666af5', '_collection_name': 'my_documents'}}]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525656ab0a6010de</th>\n",
       "      <td>ChatGroq</td>\n",
       "      <td>LLM</td>\n",
       "      <td>{\"messages\": [[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"Answer the following question based on the given context. Be concise.\\n\\nContext: . Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).\\n\\n2. Philosophical questions about AI agency and responsibility\\n3. Regulatory compliance across multiple jurisdictions\\n4. Impact on market dynamics and competitive positioning\\n\\nQuestion: What information is available in the context?\\n\\nAnswer:\", \"type\": \"human\"}}]]}</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'message.role': 'assistant', 'message.content': 'The context provides information about a regulation related to autonomous actions affecting certain systems (Category A systems) in the context of AI. It mentions that operators must maintain comprehensive documentation of decision paths for these autonomous actions. However, it does not provide information about philosophical questions, regulatory compliance across multiple jurisdictions, or impact on market dynamics and competitive positioning.'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            attributes.llm.output_messages\n",
       "context.span_id                         ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "ebed2652caff587f  VectorStoreRetriever  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      None\n",
       "525656ab0a6010de              ChatGroq  ...  [{'message.role': 'assistant', 'message.content': 'The context provides information about a regulation related to autonomous actions affecting certain systems (Category A systems) in the context of AI. It mentions that operators must maintain comprehensive documentation of decision paths for these autonomous actions. However, it does not provide information about philosophical questions, regulatory compliance across multiple jurisdictions, or impact on market dynamics and competitive positioning.'}]\n",
       "\n",
       "[2 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans_df = px.Client().get_spans_dataframe(project_name=\"Phoenix_Capabilities_Testing\")\n",
    "spans_df[[\"name\", \"span_kind\", \"attributes.input.value\", \"attributes.retrieval.documents\",\"attributes.llm.output_messages\"]].head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c989f7af-01a3-42a5-bedc-165ddfa4c954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sampled_chunks = pd.DataFrame({\"text\": all_chunks})\n",
    "sample_size = min(4, len(sampled_chunks))\n",
    "sampled_chunks = sampled_chunks.sample(n=sample_size, random_state=42)\n",
    "\n",
    "def clean_and_parse_response(response_text):\n",
    "    \"\"\"Clean and parse the response text into valid JSON.\"\"\"\n",
    "    try:\n",
    "        cleaned = response_text.strip()\n",
    "        start = cleaned.find('{')\n",
    "        end = cleaned.rfind('}')\n",
    "        \n",
    "        if start != -1 and end != -1:\n",
    "            cleaned = cleaned[start:end+1]\n",
    "        \n",
    "        result = json.loads(cleaned)\n",
    "        \n",
    "        required_keys = ['question_1', 'question_2', 'question_3']\n",
    "        if not all(key in result for key in required_keys):\n",
    "            raise ValueError(\"Missing required question keys\")\n",
    "            \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Parsing error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Generate questions\n",
    "questions = []\n",
    "for idx, row in sampled_chunks.iterrows():\n",
    "    try:\n",
    "        chunk_text = row['text'][:500]  # Limit chunk size\n",
    "        \n",
    "        response = question_chain.invoke({\"text\": chunk_text})\n",
    "        parsed = clean_and_parse_response(response['text'])\n",
    "        \n",
    "        questions.append({\n",
    "            \"text\": row['text'],  # Keep the original text chunk\n",
    "            \"question_1\": parsed['question_1'],\n",
    "            \"question_2\": parsed['question_2'],\n",
    "            \"question_3\": parsed['question_3']\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process chunk {idx + 1}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Create questions dataframe\n",
    "questions_df = pd.DataFrame(questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e015a46e-b820-4358-bb65-4e45af9f83d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# LLM_Generate by Phoneix (provide dby phoenix to generate questions)\n",
    "import json\n",
    "\n",
    "from phoenix.evals import OpenAIModel, llm_generate\n",
    "\n",
    "\n",
    "def output_parser(response: str, index: int):\n",
    "    try:\n",
    "        return json.loads(response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\"__error__\": str(e)}\n",
    "\n",
    "\n",
    "questions_df = llm_generate(\n",
    "    dataframe=document_chunks_df,\n",
    "    template=generate_questions_template,\n",
    "    model=OpenAIModel(model=\"gpt-3.5-turbo\"),\n",
    "    output_parser=output_parser,\n",
    "    concurrency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfbeb54c-5938-4453-9712-7407d7ec785c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b521af57154aeabdfbc2aba07c874c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_generate |          | 0/5 (0.0%) | ⏳ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-91af121fc4514f738ac0413903d84452\", \"tr-f20d4e3640d64860beb80c64bc5f2d48\", \"tr-a8c35e010280458caa94e7379c0a9bf3\", \"tr-7972dc426f8d4cacb649bea6bd317cc5\", \"tr-e730c68a0fcc4637bcc7ce448026192a\"]",
      "text/plain": [
       "[Trace(request_id=tr-91af121fc4514f738ac0413903d84452), Trace(request_id=tr-f20d4e3640d64860beb80c64bc5f2d48), Trace(request_id=tr-a8c35e010280458caa94e7379c0a9bf3), Trace(request_id=tr-7972dc426f8d4cacb649bea6bd317cc5), Trace(request_id=tr-e730c68a0fcc4637bcc7ce448026192a)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from phoenix.evals import LiteLLMModel, llm_generate\n",
    "\n",
    "sampled_chunks = pd.DataFrame({\"text\": all_chunks})\n",
    "sample_size = min(5, len(sampled_chunks))\n",
    "sampled_chunks = sampled_chunks.sample(n=sample_size, random_state=42)\n",
    "\n",
    "\n",
    "def output_parser(response: str, index: int):\n",
    "    try:\n",
    "        return json.loads(response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\"__error__\": str(e)}\n",
    "\n",
    "questions_df = llm_generate(\n",
    "    dataframe=sampled_chunks,\n",
    "    template=generate_questions_template,\n",
    "    model=LiteLLMModel(model=\"azure/gpt-35-turbo\"),\n",
    "    output_parser=output_parser,\n",
    "    concurrency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d9f1f1a-3570-4b9c-ad98-8846bb39b8c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>question_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "      <td>According to the context information, what is the implication of consciousness being primary?</td>\n",
       "      <td>Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What is the 'substantial factor' test and which courts have adopted it?</td>\n",
       "      <td>What is the traditional causation standard for algorithmic influence assessment and how has it been modified?</td>\n",
       "      <td>What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the perspective proposed by some theorists regarding consciousness and reality?</td>\n",
       "      <td>How does the perspective of consciousness being fundamental to reality challenge materialist and dualist frameworks?</td>\n",
       "      <td>What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "      <td>What is the definition of Category A systems as per Appendix II-B?</td>\n",
       "      <td>What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?</td>\n",
       "      <td>What are strong interactions in the context of quantum chromodynamics (QCD)?</td>\n",
       "      <td>What is the role of quarks and gluons in quantum chromodynamics (QCD)?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              question_1  ...                                                                                                                                                                          question_3\n",
       "9                                                                     What is the participatory anthropic principle proposed by Wheeler?  ...                                                    Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.\n",
       "25                                                               What is the 'substantial factor' test and which courts have adopted it?  ...                                                                                  What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?\n",
       "8                                                What is the perspective proposed by some theorists regarding consciousness and reality?  ...                                                                   What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?\n",
       "21  What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?  ...  What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?\n",
       "0                                                        What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?  ...                                                                                                              What is the role of quarks and gluons in quantum chromodynamics (QCD)?\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50a0528e-b294-4b68-aaf7-7297be4013d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Construct a dataframe of the questions and the document chunks\n",
    "questions_with_document_chunk_df = pd.concat([questions_df, sampled_chunks], axis=1)\n",
    "questions_with_document_chunk_df = questions_with_document_chunk_df.melt(\n",
    "    id_vars=[\"text\"], value_name=\"question\"\n",
    ").drop(\"variable\", axis=1)\n",
    "# If the above step was interrupted, there might be questions missing. Let's run this to clean up the dataframe.\n",
    "questions_with_document_chunk_df = questions_with_document_chunk_df[\n",
    "    questions_with_document_chunk_df[\"question\"].notnull()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e46ad25-70ab-4e03-bbba-7aa751594f29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states</td>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>. Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"</td>\n",
       "      <td>What is the 'substantial factor' test and which courts have adopted it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>. Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.</td>\n",
       "      <td>What is the perspective proposed by some theorists regarding consciousness and reality?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).</td>\n",
       "      <td>What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons</td>\n",
       "      <td>What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states</td>\n",
       "      <td>According to the context information, what is the implication of consciousness being primary?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>. Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"</td>\n",
       "      <td>What is the traditional causation standard for algorithmic influence assessment and how has it been modified?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>. Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.</td>\n",
       "      <td>How does the perspective of consciousness being fundamental to reality challenge materialist and dualist frameworks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).</td>\n",
       "      <td>What is the definition of Category A systems as per Appendix II-B?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons</td>\n",
       "      <td>What are strong interactions in the context of quantum chromodynamics (QCD)?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states</td>\n",
       "      <td>Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>. Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"</td>\n",
       "      <td>What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>. Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.</td>\n",
       "      <td>What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).</td>\n",
       "      <td>What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons</td>\n",
       "      <td>What is the role of quarks and gluons in quantum chromodynamics (QCD)?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                            text                                                                                                                                                                            question\n",
       "0   Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states                                                                                                                  What is the participatory anthropic principle proposed by Wheeler?\n",
       "1                            . Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"                                                                                                             What is the 'substantial factor' test and which courts have adopted it?\n",
       "2                                                                              . Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.                                                                                             What is the perspective proposed by some theorists regarding consciousness and reality?\n",
       "3                                                                  . Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).                                                What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?\n",
       "4                                                                                    The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons                                                                                                     What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?\n",
       "5   Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states                                                                                       According to the context information, what is the implication of consciousness being primary?\n",
       "6                            . Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"                                                                       What is the traditional causation standard for algorithmic influence assessment and how has it been modified?\n",
       "7                                                                              . Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.                                                                How does the perspective of consciousness being fundamental to reality challenge materialist and dualist frameworks?\n",
       "8                                                                  . Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).                                                                                                                  What is the definition of Category A systems as per Appendix II-B?\n",
       "9                                                                                    The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons                                                                                                        What are strong interactions in the context of quantum chromodynamics (QCD)?\n",
       "10  Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states                                                    Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.\n",
       "11                           . Some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, while others maintain traditional \"but for\" causation standards with modifications for algorithmic influence assessment.\"\"\"                                                                                  What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?\n",
       "12                                                                             . Some theorists propose that consciousness might be fundamental to reality rather than emergent from it - a perspective that challenges both materialist and dualist frameworks.                                                                   What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?\n",
       "13                                                                 . Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).  What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?\n",
       "14                                                                                   The Standard Model's conceptualization of quantum chromodynamics (QCD) represents a sophisticated framework for understanding strong interactions between quarks and gluons                                                                                                              What is the role of quarks and gluons in quantum chromodynamics (QCD)?"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_with_document_chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9739580-dbc9-4070-a5f1-65384ae4fac2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# questions_df\n",
    "# questions_with_document_chunk_df = questions_df.melt(\n",
    "#     id_vars=[\"text\"], value_name=\"question\"\n",
    "# ).drop(\"variable\", axis=1)\n",
    "# # If the above step was interrupted, there might be questions missing. Let's run this to clean up the dataframe.\n",
    "# questions_with_document_chunk_df = questions_with_document_chunk_df[\n",
    "#     questions_with_document_chunk_df[\"question\"].notnull()\n",
    "# ]\n",
    "# questions_with_document_chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21d8bc20-3ac9-484e-8089-6b3a7c8982f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(15, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_with_document_chunk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7499ae68-9459-405d-8ddc-de79e9269c58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/10 08:48:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:558: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nProcessing question 1/15:\nQuestion: What is the participatory anthropic principle proposed by Wheeler?\nAnswer: The participatory anthropic principle, proposed by Wheeler, suggests that observers are necessary fo...\n\nProcessing question 2/15:\nQuestion: What is the 'substantial factor' test and which courts have adopted it?\nAnswer: The 'substantial factor' test is a legal standard outlined in the Model Autonomous Systems Code, whi...\n\nProcessing question 3/15:\nQuestion: What is the perspective proposed by some theorists regarding consciousness and reality?\nAnswer: Some theorists propose that consciousness is fundamental to reality, rather than it being emergent f...\n\nProcessing question 4/15:\nQuestion: What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?\nAnswer: Operators must maintain comprehensive documentation of decision paths for any autonomous actions aff...\n\nProcessing question 5/15:\nQuestion: What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?\nAnswer: The Standard Model's conceptualization of QCD is a theory that explains the strong interactions betw...\n\nCompleted 5/15 questions\n\nProcessing question 6/15:\nQuestion: According to the context information, what is the implication of consciousness being primary?\nAnswer: If consciousness is primary, it implies that objective reality may not exist independently of observ...\n\nProcessing question 7/15:\nQuestion: What is the traditional causation standard for algorithmic influence assessment and how has it been modified?\nAnswer: The traditional \"but for\" causation standard requires that an event or action would not have occurre...\n\nProcessing question 8/15:\nQuestion: How does the perspective of consciousness being fundamental to reality challenge materialist and dualist frameworks?\nAnswer: This perspective challenges materialist frameworks because it contradicts the belief that reality is...\n\nProcessing question 9/15:\nQuestion: What is the definition of Category A systems as per Appendix II-B?\nAnswer: The context does not provide the definition of Category A systems as per Appendix II-B. It only ment...\n\nProcessing question 10/15:\nQuestion: What are strong interactions in the context of quantum chromodynamics (QCD)?\nAnswer: In the context of QCD, strong interactions refer to the fundamental force that binds quarks and gluo...\n\nCompleted 10/15 questions\n\nProcessing question 11/15:\nQuestion: Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.\nAnswer: According to the context, if consciousness is primary, objective reality may not exist independent o...\n\nProcessing question 12/15:\nQuestion: What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?\nAnswer: The Model Autonomous Systems Code is a proposed set of guidelines for regulating autonomous systems....\n\nProcessing question 13/15:\nQuestion: What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?\nAnswer: The emergent perspective posits that consciousness arises from a pre-existing reality, typically phy...\n\nProcessing question 14/15:\nQuestion: What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?\nAnswer: The given context specifies that the requirement for operators to maintain comprehensive documentati...\n\nProcessing question 15/15:\nQuestion: What is the role of quarks and gluons in quantum chromodynamics (QCD)?\nAnswer: In Quantum Chromodynamics (QCD), quarks and gluons are the fundamental particles responsible for str...\n\nCompleted 15/15 questions\n\nProcessing complete! Generated 15 QA pairs\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-6fe2ab00f80545a3b5a4f5109e19507b\", \"tr-f7d57a6fcc28485f9e3ac440e76583a4\", \"tr-38558f628c734bbf9a37d3c77ceba32a\", \"tr-9bc4d4d9c6b24edba546da0b6cf7c36e\", \"tr-2fd2c434900448d1887d97b48b1aecfb\", \"tr-a0dc6d0ed1fb44e692ae2f30e5306a4a\", \"tr-1e85c9e187fa4b98abc33b5f040595f7\", \"tr-14a38e21e53748248e3001f77365df5a\", \"tr-61d5a2a1dc9f4d9eac8f968b67eac91b\", \"tr-10837444a9144d40b81710b8084b6ca8\"]",
      "text/plain": [
       "[Trace(request_id=tr-6fe2ab00f80545a3b5a4f5109e19507b), Trace(request_id=tr-f7d57a6fcc28485f9e3ac440e76583a4), Trace(request_id=tr-38558f628c734bbf9a37d3c77ceba32a), Trace(request_id=tr-9bc4d4d9c6b24edba546da0b6cf7c36e), Trace(request_id=tr-2fd2c434900448d1887d97b48b1aecfb), Trace(request_id=tr-a0dc6d0ed1fb44e692ae2f30e5306a4a), Trace(request_id=tr-1e85c9e187fa4b98abc33b5f040595f7), Trace(request_id=tr-14a38e21e53748248e3001f77365df5a), Trace(request_id=tr-61d5a2a1dc9f4d9eac8f968b67eac91b), Trace(request_id=tr-10837444a9144d40b81710b8084b6ca8)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_qa_pairs(questions_df, retriever, qa_chain, max_context_length=1000, docs_per_question=2):\n",
    "    \"\"\"\n",
    "    Generate question-answer pairs with retrieved context.\n",
    "    \n",
    "    Args:\n",
    "        questions_df (pd.DataFrame): DataFrame containing questions with 'text' and 'question' columns\n",
    "        retriever: Document retriever instance\n",
    "        qa_chain: QA chain instance\n",
    "        max_context_length (int): Maximum length for context\n",
    "        docs_per_question (int): Number of documents to use for context\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing QA pairs with context\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    total_questions = len(questions_df)\n",
    "    \n",
    "    if questions_df.empty:\n",
    "        print(\"No questions to process!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    for idx, row in questions_df.iterrows():\n",
    "        try:\n",
    "            question = row['question']\n",
    "            print(f\"\\nProcessing question {idx + 1}/{total_questions}:\")\n",
    "            print(f\"Question: {question}\")\n",
    "            \n",
    "            # Retrieve relevant documents\n",
    "            relevant_docs = retriever.get_relevant_documents(question)\n",
    "            context = \" \".join([doc.page_content for doc in relevant_docs[:docs_per_question]])\n",
    "            \n",
    "            # Truncate context if needed\n",
    "            if len(context) > max_context_length:\n",
    "                context = context[:max_context_length] + \"...\"\n",
    "            \n",
    "            # Generate answer - using 'query' instead of 'question'\n",
    "            response = qa_chain({\n",
    "                \"query\": question\n",
    "            })\n",
    "            \n",
    "            # Store results\n",
    "            qa_pair = {\n",
    "                \"text\": row['text'],\n",
    "                \"question\": question,\n",
    "                \"answer\": response[\"result\"],\n",
    "                \"context\": context,\n",
    "                \"context_length\": len(context)\n",
    "            }\n",
    "            \n",
    "            print(f\"Answer: {qa_pair['answer'][:100]}...\")  # Print first 100 chars of answer\n",
    "            qa_pairs.append(qa_pair)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {idx + 1}: {str(e)}\")\n",
    "            # Add error entry to maintain data consistency\n",
    "            qa_pairs.append({\n",
    "                \"text\": row['text'],\n",
    "                \"question\": question,\n",
    "                \"answer\": f\"Error generating answer: {str(e)}\",\n",
    "                \"context\": \"\",\n",
    "                \"context_length\": 0\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Print progress\n",
    "        if (idx + 1) % 5 == 0:\n",
    "            print(f\"\\nCompleted {idx + 1}/{total_questions} questions\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    qa_df = pd.DataFrame(qa_pairs)\n",
    "    \n",
    "    # Add quality metrics\n",
    "    qa_df['answer_length'] = qa_df['answer'].str.len()\n",
    "    qa_df['question_length'] = qa_df['question'].str.len()\n",
    "    \n",
    "    print(f\"\\nProcessing complete! Generated {len(qa_df)} QA pairs\")\n",
    "    \n",
    "    return qa_df\n",
    "\n",
    "# Generate QA pairs\n",
    "qa_df = generate_qa_pairs(\n",
    "    questions_df=questions_with_document_chunk_df,\n",
    "    retriever=retriever,\n",
    "    qa_chain=qa_chain,\n",
    "    max_context_length=1000,\n",
    "    docs_per_question=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c3b8e5-d05c-4809-aafe-0f0a543bde4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(62, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.session.evaluation import get_retrieved_documents\n",
    "\n",
    "retrieved_documents_df = get_retrieved_documents(px.Client())\n",
    "retrieved_documents_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50cac5f6-ac25-408c-9b93-5d369bf7cc19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes available in phoenix.evals:\nAnthropicModel\nBedrockModel\nClassificationTemplate\nGeminiModel\nHallucinationEvaluator\nLLMEvaluator\nLiteLLMModel\nMistralAIModel\nOpenAIModel\nPromptTemplate\nQAEvaluator\nRelevanceEvaluator\nSQLEvaluator\nSummarizationEvaluator\nToxicityEvaluator\nVertexAIModel\n"
     ]
    }
   ],
   "source": [
    "import phoenix.evals\n",
    "\n",
    "module_attrs = dir(phoenix.evals)\n",
    "\n",
    "module_classes = [attr for attr in module_attrs if isinstance(getattr(phoenix.evals, attr), type)]\n",
    "print(\"Classes available in phoenix.evals:\")\n",
    "for cls in module_classes:\n",
    "    print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e060ded-3f86-40fe-886f-f3f41e1f95f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter your Gemini API key:  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from phoenix.evals import (\n",
    "    RelevanceEvaluator,\n",
    "    run_evals,\n",
    "    LiteLLMModel\n",
    ")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if not (gemini_api_key := os.getenv(\"GEMINI_API_KEY\")):\n",
    "    gemini_api_key = input(\"Enter your Gemini API key: \")\n",
    "os.environ[\"GEMINI_API_KEY\"] = gemini_api_key\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(LiteLLMModel(\n",
    "    model=\"gemini/gemini-pro\"\n",
    "))\n",
    "\n",
    "\n",
    "retrieved_documents_relevance_df = run_evals(\n",
    "    evaluators=[relevance_evaluator],\n",
    "    dataframe=retrieved_documents_df,\n",
    "    provide_explanation=True,\n",
    "    concurrency=5\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "202850a0-5ba8-4b37-a7a0-9bc57e76da74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3221ea1676664388b96a71aacc567f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "run_evals |          | 0/62 (0.0%) | ⏳ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-ac7c9c026cad4db4abf3af22314fd31b\", \"tr-f207cf34114c4f689d1597e3a19418db\", \"tr-bb268b2b7315415399b4e25f2de15e0f\", \"tr-a53b18e95d514f149074b7a76a5c129c\", \"tr-f2fdd00e10f0490bb00b17fa77192dec\", \"tr-17039d6bd0ab474f9ae790144407b0d1\", \"tr-445a0d83650a4735a118133d5f41342d\", \"tr-082024123adb4b219ad8c3b407711b2e\", \"tr-7fffb3838fa64fb28c78a614f2a756d6\", \"tr-3eac1fc4c2d34c6a837e953a1dcd2c03\"]",
      "text/plain": [
       "[Trace(request_id=tr-ac7c9c026cad4db4abf3af22314fd31b), Trace(request_id=tr-f207cf34114c4f689d1597e3a19418db), Trace(request_id=tr-bb268b2b7315415399b4e25f2de15e0f), Trace(request_id=tr-a53b18e95d514f149074b7a76a5c129c), Trace(request_id=tr-f2fdd00e10f0490bb00b17fa77192dec), Trace(request_id=tr-17039d6bd0ab474f9ae790144407b0d1), Trace(request_id=tr-445a0d83650a4735a118133d5f41342d), Trace(request_id=tr-082024123adb4b219ad8c3b407711b2e), Trace(request_id=tr-7fffb3838fa64fb28c78a614f2a756d6), Trace(request_id=tr-3eac1fc4c2d34c6a837e953a1dcd2c03)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from phoenix.evals import (\n",
    "    RelevanceEvaluator,\n",
    "    run_evals,\n",
    "    LiteLLMModel\n",
    ")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(LiteLLMModel(\n",
    "    model=\"azure/gpt-35-turbo\"\n",
    "))\n",
    "\n",
    "retrieved_documents_relevance_df = run_evals(\n",
    "    evaluators=[relevance_evaluator],\n",
    "    dataframe=retrieved_documents_df,\n",
    "    provide_explanation=True,\n",
    "    concurrency=5\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4ab0fa4-277d-4aaf-88eb-5a9838decb4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th>document_position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ebed2652caff587f</th>\n",
       "      <th>0</th>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text mentions that operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems. However, it does not provide any specific information about what information is available in the context. Therefore, the reference text is unrelated to the question.\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text lists three topics: philosophical questions about AI agency and responsibility, regulatory compliance across multiple jurisdictions, and impact on market dynamics and competitive positioning. None of these topics directly answer the question of what information is available in the context. Therefore, the label is \"unrelated\". \\n\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ae9aac0c4949b401</th>\n",
       "      <th>0</th>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text does not contain any information about the participatory anthropic principle proposed by Wheeler. It discusses an illusion related to individuality, but this is not relevant to the question.\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9b2b9bef04cb96db</th>\n",
       "      <th>0</th>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        label  ...                                                                                                                                                                                                                                                                                                                                                                      explanation\n",
       "context.span_id  document_position             ...                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "ebed2652caff587f 0                  unrelated  ...                          The reference text mentions that operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems. However, it does not provide any specific information about what information is available in the context. Therefore, the reference text is unrelated to the question.\\nLABEL: unrelated\n",
       "                 1                  unrelated  ...  The reference text lists three topics: philosophical questions about AI agency and responsibility, regulatory compliance across multiple jurisdictions, and impact on market dynamics and competitive positioning. None of these topics directly answer the question of what information is available in the context. Therefore, the label is \"unrelated\". \\n\\nLABEL: unrelated\n",
       "ae9aac0c4949b401 0                   relevant  ...                 The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant\n",
       "                 1                  unrelated  ...                                                                                                                                              The reference text does not contain any information about the participatory anthropic principle proposed by Wheeler. It discusses an illusion related to individuality, but this is not relevant to the question.\\nLABEL: unrelated\n",
       "9b2b9bef04cb96db 0                   relevant  ...                 The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents_relevance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5101190e-5947-4924-9e2f-002eee918162",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "documents_with_relevance_df = pd.concat(\n",
    "    [retrieved_documents_df, retrieved_documents_relevance_df.add_prefix(\"eval_\")], axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad7f2d56-af03-46b1-9e1b-6b0f9d3a59b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>input</th>\n",
       "      <th>reference</th>\n",
       "      <th>eval_label</th>\n",
       "      <th>eval_score</th>\n",
       "      <th>eval_explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th>document_position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">e6e8a53c4fc30767</th>\n",
       "      <th>0</th>\n",
       "      <td>c4493a2c76d3cfdf1f2e7e43fdbc04ec</td>\n",
       "      <td>What information is available in the context?</td>\n",
       "      <td>. Pursuant to subsection (c)(2), operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems (as defined in Appendix II-B).</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text mentions that operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems. However, it does not provide any specific information about what information is available in the context. Therefore, the reference text is unrelated to the question.\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4493a2c76d3cfdf1f2e7e43fdbc04ec</td>\n",
       "      <td>What information is available in the context?</td>\n",
       "      <td>2. Philosophical questions about AI agency and responsibility\\n3. Regulatory compliance across multiple jurisdictions\\n4. Impact on market dynamics and competitive positioning</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text lists three topics: philosophical questions about AI agency and responsibility, regulatory compliance across multiple jurisdictions, and impact on market dynamics and competitive positioning. None of these topics directly answer the question of what information is available in the context. Therefore, the label is \"unrelated\". \\n\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">950905a084b6365b</th>\n",
       "      <th>0</th>\n",
       "      <td>e83918b83b3d9d19d8884b8abc9ba4c9</td>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "      <td>Consider the implications: if consciousness is primary, does objective reality exist independent of observation? This recalls Wheeler's participatory anthropic principle, suggesting that observers are necessary for the actualization of potential states</td>\n",
       "      <td>relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e83918b83b3d9d19d8884b8abc9ba4c9</td>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "      <td>. Yet this illusion appears necessary for practical functioning, creating a paradox where we must simultaneously accept and reject our apparent individuality.\"\"\"</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0</td>\n",
       "      <td>The reference text does not contain any information about the participatory anthropic principle proposed by Wheeler. It discusses an illusion related to individuality, but this is not relevant to the question.\\nLABEL: unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    context.trace_id  ...                                                                                                                                                                                                                                                                                                                                                                 eval_explanation\n",
       "context.span_id  document_position                                    ...                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "e6e8a53c4fc30767 0                  c4493a2c76d3cfdf1f2e7e43fdbc04ec  ...                          The reference text mentions that operators must maintain comprehensive documentation of decision paths for any autonomous actions affecting Category A systems. However, it does not provide any specific information about what information is available in the context. Therefore, the reference text is unrelated to the question.\\nLABEL: unrelated\n",
       "                 1                  c4493a2c76d3cfdf1f2e7e43fdbc04ec  ...  The reference text lists three topics: philosophical questions about AI agency and responsibility, regulatory compliance across multiple jurisdictions, and impact on market dynamics and competitive positioning. None of these topics directly answer the question of what information is available in the context. Therefore, the label is \"unrelated\". \\n\\nLABEL: unrelated\n",
       "950905a084b6365b 0                  e83918b83b3d9d19d8884b8abc9ba4c9  ...                 The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The question asks about this principle proposed by Wheeler. Therefore, the reference text is directly related to the question and contains information that can help answer it.\\nLABEL: relevant\n",
       "                 1                  e83918b83b3d9d19d8884b8abc9ba4c9  ...                                                                                                                                              The reference text does not contain any information about the participatory anthropic principle proposed by Wheeler. It discusses an illusion related to individuality, but this is not relevant to the question.\\nLABEL: unrelated\n",
       "\n",
       "[4 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_with_relevance_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce83befd-46da-4e48-abbd-82d04e100efc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4402110491910889>, line 18\u001B[0m\n",
       "\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n",
       "\u001B[1;32m     14\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan\n",
       "\u001B[1;32m     17\u001B[0m ndcg_at_2 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\n",
       "\u001B[0;32m---> 18\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m: documents_with_relevance_df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext.span_id\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mapply(_compute_ndcg, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)}\n",
       "\u001B[1;32m     19\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1588\u001B[0m, in \u001B[0;36mGroupBy.apply\u001B[0;34m(self, func, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1580\u001B[0m             new_msg \u001B[38;5;241m=\u001B[39m (\n",
       "\u001B[1;32m   1581\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe operation \u001B[39m\u001B[38;5;132;01m{\u001B[39;00morig_func\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m failed on a column. If any error \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1582\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis raised, this will raise an exception in a future version \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1583\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof pandas. Drop these columns to avoid this warning.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1584\u001B[0m             )\n",
       "\u001B[1;32m   1585\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m rewrite_warning(\n",
       "\u001B[1;32m   1586\u001B[0m                 old_msg, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, new_msg\n",
       "\u001B[1;32m   1587\u001B[0m             ) \u001B[38;5;28;01mif\u001B[39;00m is_np_func \u001B[38;5;28;01melse\u001B[39;00m nullcontext():\n",
       "\u001B[0;32m-> 1588\u001B[0m                 \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_python_apply_general(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selected_obj)\n",
       "\u001B[1;32m   1590\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1629\u001B[0m, in \u001B[0;36mGroupBy._python_apply_general\u001B[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001B[0m\n",
       "\u001B[1;32m   1592\u001B[0m \u001B[38;5;129m@final\u001B[39m\n",
       "\u001B[1;32m   1593\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_python_apply_general\u001B[39m(\n",
       "\u001B[1;32m   1594\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1599\u001B[0m     is_agg: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m   1600\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NDFrameT:\n",
       "\u001B[1;32m   1601\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m   1602\u001B[0m \u001B[38;5;124;03m    Apply function f in python space\u001B[39;00m\n",
       "\u001B[1;32m   1603\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1627\u001B[0m \u001B[38;5;124;03m        data after applying f\u001B[39;00m\n",
       "\u001B[1;32m   1628\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 1629\u001B[0m     values, mutated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrouper\u001B[38;5;241m.\u001B[39mapply(f, data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis)\n",
       "\u001B[1;32m   1630\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m not_indexed_same \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m   1631\u001B[0m         not_indexed_same \u001B[38;5;241m=\u001B[39m mutated \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmutated\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/ops.py:839\u001B[0m, in \u001B[0;36mBaseGrouper.apply\u001B[0;34m(self, f, data, axis)\u001B[0m\n",
       "\u001B[1;32m    837\u001B[0m \u001B[38;5;66;03m# group might be modified\u001B[39;00m\n",
       "\u001B[1;32m    838\u001B[0m group_axes \u001B[38;5;241m=\u001B[39m group\u001B[38;5;241m.\u001B[39maxes\n",
       "\u001B[0;32m--> 839\u001B[0m res \u001B[38;5;241m=\u001B[39m f(group)\n",
       "\u001B[1;32m    840\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mutated \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_indexed_like(res, group_axes, axis):\n",
       "\u001B[1;32m    841\u001B[0m     mutated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1540\u001B[0m, in \u001B[0;36mGroupBy.apply.<locals>.f\u001B[0;34m(g)\u001B[0m\n",
       "\u001B[1;32m   1537\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n",
       "\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf\u001B[39m(g):\n",
       "\u001B[1;32m   1539\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[0;32m-> 1540\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(g, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\n",
       "File \u001B[0;32m<command-4402110491910889>, line 12\u001B[0m, in \u001B[0;36m_compute_ndcg\u001B[0;34m(df, k)\u001B[0m\n",
       "\u001B[1;32m     10\u001B[0m eval_scores[: \u001B[38;5;28mlen\u001B[39m(df)] \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39meval_score\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ndcg_score([eval_scores], k\u001B[38;5;241m=\u001B[39mk)\n",
       "\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n",
       "\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:580\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    578\u001B[0m     patch_function\u001B[38;5;241m.\u001B[39mcall(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 580\u001B[0m     patch_function(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    582\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    584\u001B[0m try_log_autologging_event(\n",
       "\u001B[1;32m    585\u001B[0m     AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_patch_function_success,\n",
       "\u001B[1;32m    586\u001B[0m     session,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    590\u001B[0m     kwargs,\n",
       "\u001B[1;32m    591\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/sklearn/__init__.py:1718\u001B[0m, in \u001B[0;36m_autolog.<locals>.patched_metric_api\u001B[0;34m(original, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1714\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mshould_log_post_training_metrics():\n",
       "\u001B[1;32m   1715\u001B[0m     \u001B[38;5;66;03m# one metric api may call another metric api,\u001B[39;00m\n",
       "\u001B[1;32m   1716\u001B[0m     \u001B[38;5;66;03m# to avoid this, call disable_log_post_training_metrics to avoid nested patch\u001B[39;00m\n",
       "\u001B[1;32m   1717\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mdisable_log_post_training_metrics():\n",
       "\u001B[0;32m-> 1718\u001B[0m         metric \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m   1720\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mis_metric_value_loggable(metric):\n",
       "\u001B[1;32m   1721\u001B[0m         metric_name \u001B[38;5;241m=\u001B[39m original\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:561\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n",
       "\u001B[1;32m    558\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n",
       "\u001B[1;32m    559\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
       "\u001B[0;32m--> 561\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:496\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n",
       "\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m    488\u001B[0m     try_log_autologging_event(\n",
       "\u001B[1;32m    489\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_start,\n",
       "\u001B[1;32m    490\u001B[0m         session,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    494\u001B[0m         og_kwargs,\n",
       "\u001B[1;32m    495\u001B[0m     )\n",
       "\u001B[0;32m--> 496\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m original_fn(\u001B[38;5;241m*\u001B[39mog_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mog_kwargs)\n",
       "\u001B[1;32m    498\u001B[0m     try_log_autologging_event(\n",
       "\u001B[1;32m    499\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_success,\n",
       "\u001B[1;32m    500\u001B[0m         session,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    504\u001B[0m         og_kwargs,\n",
       "\u001B[1;32m    505\u001B[0m     )\n",
       "\u001B[1;32m    506\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:558\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n",
       "\u001B[1;32m    550\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n",
       "\u001B[1;32m    551\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n",
       "\u001B[1;32m    552\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n",
       "\u001B[1;32m    553\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n",
       "\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n",
       "\u001B[1;32m    555\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    556\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    557\u001B[0m ):\n",
       "\u001B[0;32m--> 558\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n",
       "\u001B[1;32m    559\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n",
       "\u001B[1;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
       "\u001B[0;32m--> 191\u001B[0m params \u001B[38;5;241m=\u001B[39m func_sig\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    192\u001B[0m params\u001B[38;5;241m.\u001B[39mapply_defaults()\n",
       "\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# ignore self/cls and positional/keyword markers\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3242\u001B[0m, in \u001B[0;36mSignature.bind\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   3237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbind\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m/\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n",
       "\u001B[1;32m   3238\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001B[39;00m\n",
       "\u001B[1;32m   3239\u001B[0m \u001B[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001B[39;00m\n",
       "\u001B[1;32m   3240\u001B[0m \u001B[38;5;124;03m    if the passed arguments can not be bound.\u001B[39;00m\n",
       "\u001B[1;32m   3241\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 3242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bind(args, kwargs)\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3157\u001B[0m, in \u001B[0;36mSignature._bind\u001B[0;34m(self, args, kwargs, partial)\u001B[0m\n",
       "\u001B[1;32m   3155\u001B[0m                 msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmissing a required\u001B[39m\u001B[38;5;132;01m{argtype}\u001B[39;00m\u001B[38;5;124m argument: \u001B[39m\u001B[38;5;132;01m{arg!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n",
       "\u001B[1;32m   3156\u001B[0m                 msg \u001B[38;5;241m=\u001B[39m msg\u001B[38;5;241m.\u001B[39mformat(arg\u001B[38;5;241m=\u001B[39mparam\u001B[38;5;241m.\u001B[39mname, argtype\u001B[38;5;241m=\u001B[39margtype)\n",
       "\u001B[0;32m-> 3157\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   3158\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   3159\u001B[0m     \u001B[38;5;66;03m# We have a positional argument to process\u001B[39;00m\n",
       "\u001B[1;32m   3160\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: missing a required argument: 'y_score'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "TypeError",
        "evalue": "missing a required argument: 'y_score'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: missing a required argument: 'y_score'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-4402110491910889>, line 18\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan\n\u001B[1;32m     17\u001B[0m ndcg_at_2 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\n\u001B[0;32m---> 18\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m: documents_with_relevance_df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext.span_id\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mapply(_compute_ndcg, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)}\n\u001B[1;32m     19\u001B[0m )\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1588\u001B[0m, in \u001B[0;36mGroupBy.apply\u001B[0;34m(self, func, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1580\u001B[0m             new_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1581\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe operation \u001B[39m\u001B[38;5;132;01m{\u001B[39;00morig_func\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m failed on a column. If any error \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1582\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis raised, this will raise an exception in a future version \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1583\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof pandas. Drop these columns to avoid this warning.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1584\u001B[0m             )\n\u001B[1;32m   1585\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m rewrite_warning(\n\u001B[1;32m   1586\u001B[0m                 old_msg, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, new_msg\n\u001B[1;32m   1587\u001B[0m             ) \u001B[38;5;28;01mif\u001B[39;00m is_np_func \u001B[38;5;28;01melse\u001B[39;00m nullcontext():\n\u001B[0;32m-> 1588\u001B[0m                 \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_python_apply_general(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selected_obj)\n\u001B[1;32m   1590\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1629\u001B[0m, in \u001B[0;36mGroupBy._python_apply_general\u001B[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001B[0m\n\u001B[1;32m   1592\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[1;32m   1593\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_python_apply_general\u001B[39m(\n\u001B[1;32m   1594\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1599\u001B[0m     is_agg: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   1600\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NDFrameT:\n\u001B[1;32m   1601\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1602\u001B[0m \u001B[38;5;124;03m    Apply function f in python space\u001B[39;00m\n\u001B[1;32m   1603\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1627\u001B[0m \u001B[38;5;124;03m        data after applying f\u001B[39;00m\n\u001B[1;32m   1628\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1629\u001B[0m     values, mutated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrouper\u001B[38;5;241m.\u001B[39mapply(f, data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis)\n\u001B[1;32m   1630\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m not_indexed_same \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1631\u001B[0m         not_indexed_same \u001B[38;5;241m=\u001B[39m mutated \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmutated\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/ops.py:839\u001B[0m, in \u001B[0;36mBaseGrouper.apply\u001B[0;34m(self, f, data, axis)\u001B[0m\n\u001B[1;32m    837\u001B[0m \u001B[38;5;66;03m# group might be modified\u001B[39;00m\n\u001B[1;32m    838\u001B[0m group_axes \u001B[38;5;241m=\u001B[39m group\u001B[38;5;241m.\u001B[39maxes\n\u001B[0;32m--> 839\u001B[0m res \u001B[38;5;241m=\u001B[39m f(group)\n\u001B[1;32m    840\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mutated \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_indexed_like(res, group_axes, axis):\n\u001B[1;32m    841\u001B[0m     mutated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1540\u001B[0m, in \u001B[0;36mGroupBy.apply.<locals>.f\u001B[0;34m(g)\u001B[0m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf\u001B[39m(g):\n\u001B[1;32m   1539\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1540\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(g, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
        "File \u001B[0;32m<command-4402110491910889>, line 12\u001B[0m, in \u001B[0;36m_compute_ndcg\u001B[0;34m(df, k)\u001B[0m\n\u001B[1;32m     10\u001B[0m eval_scores[: \u001B[38;5;28mlen\u001B[39m(df)] \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39meval_score\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ndcg_score([eval_scores], k\u001B[38;5;241m=\u001B[39mk)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:580\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    578\u001B[0m     patch_function\u001B[38;5;241m.\u001B[39mcall(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 580\u001B[0m     patch_function(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    582\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    584\u001B[0m try_log_autologging_event(\n\u001B[1;32m    585\u001B[0m     AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_patch_function_success,\n\u001B[1;32m    586\u001B[0m     session,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    590\u001B[0m     kwargs,\n\u001B[1;32m    591\u001B[0m )\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/sklearn/__init__.py:1718\u001B[0m, in \u001B[0;36m_autolog.<locals>.patched_metric_api\u001B[0;34m(original, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1714\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mshould_log_post_training_metrics():\n\u001B[1;32m   1715\u001B[0m     \u001B[38;5;66;03m# one metric api may call another metric api,\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m     \u001B[38;5;66;03m# to avoid this, call disable_log_post_training_metrics to avoid nested patch\u001B[39;00m\n\u001B[1;32m   1717\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mdisable_log_post_training_metrics():\n\u001B[0;32m-> 1718\u001B[0m         metric \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1720\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mis_metric_value_loggable(metric):\n\u001B[1;32m   1721\u001B[0m         metric_name \u001B[38;5;241m=\u001B[39m original\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:561\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001B[0;34m(*og_args, **og_kwargs)\u001B[0m\n\u001B[1;32m    558\u001B[0m         original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    559\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n\u001B[0;32m--> 561\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:496\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001B[0;34m(original_fn, og_args, og_kwargs)\u001B[0m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    488\u001B[0m     try_log_autologging_event(\n\u001B[1;32m    489\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_start,\n\u001B[1;32m    490\u001B[0m         session,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    494\u001B[0m         og_kwargs,\n\u001B[1;32m    495\u001B[0m     )\n\u001B[0;32m--> 496\u001B[0m     original_fn_result \u001B[38;5;241m=\u001B[39m original_fn(\u001B[38;5;241m*\u001B[39mog_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mog_kwargs)\n\u001B[1;32m    498\u001B[0m     try_log_autologging_event(\n\u001B[1;32m    499\u001B[0m         AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_original_function_success,\n\u001B[1;32m    500\u001B[0m         session,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    504\u001B[0m         og_kwargs,\n\u001B[1;32m    505\u001B[0m     )\n\u001B[1;32m    506\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_fn_result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:558\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001B[0;34m(*_og_args, **_og_kwargs)\u001B[0m\n\u001B[1;32m    550\u001B[0m \u001B[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001B[39;00m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;66;03m# during original function execution, even if silent mode is enabled\u001B[39;00m\n\u001B[1;32m    552\u001B[0m \u001B[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001B[39;00m\n\u001B[1;32m    553\u001B[0m \u001B[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001B[39;00m\n\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001B[1;32m    555\u001B[0m     disable_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    556\u001B[0m     reroute_warnings\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    557\u001B[0m ):\n\u001B[0;32m--> 558\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;241m*\u001B[39m_og_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_og_kwargs)\n\u001B[1;32m    559\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n\u001B[0;32m--> 191\u001B[0m params \u001B[38;5;241m=\u001B[39m func_sig\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    192\u001B[0m params\u001B[38;5;241m.\u001B[39mapply_defaults()\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# ignore self/cls and positional/keyword markers\u001B[39;00m\n",
        "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3242\u001B[0m, in \u001B[0;36mSignature.bind\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbind\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m/\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   3238\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001B[39;00m\n\u001B[1;32m   3239\u001B[0m \u001B[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001B[39;00m\n\u001B[1;32m   3240\u001B[0m \u001B[38;5;124;03m    if the passed arguments can not be bound.\u001B[39;00m\n\u001B[1;32m   3241\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bind(args, kwargs)\n",
        "File \u001B[0;32m/usr/lib/python3.12/inspect.py:3157\u001B[0m, in \u001B[0;36mSignature._bind\u001B[0;34m(self, args, kwargs, partial)\u001B[0m\n\u001B[1;32m   3155\u001B[0m                 msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmissing a required\u001B[39m\u001B[38;5;132;01m{argtype}\u001B[39;00m\u001B[38;5;124m argument: \u001B[39m\u001B[38;5;132;01m{arg!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   3156\u001B[0m                 msg \u001B[38;5;241m=\u001B[39m msg\u001B[38;5;241m.\u001B[39mformat(arg\u001B[38;5;241m=\u001B[39mparam\u001B[38;5;241m.\u001B[39mname, argtype\u001B[38;5;241m=\u001B[39margtype)\n\u001B[0;32m-> 3157\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   3158\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3159\u001B[0m     \u001B[38;5;66;03m# We have a positional argument to process\u001B[39;00m\n\u001B[1;32m   3160\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
        "\u001B[0;31mTypeError\u001B[0m: missing a required argument: 'y_score'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "\n",
    "def _compute_ndcg(df: pd.DataFrame, k: int):\n",
    "    \"\"\"Compute NDCG@k in the presence of missing values\"\"\"\n",
    "    n = max(2, len(df))\n",
    "    eval_scores = np.zeros(n)\n",
    "    doc_scores = np.zeros(n)\n",
    "    eval_scores[: len(df)] = df.eval_score\n",
    "    try:\n",
    "        return ndcg_score([eval_scores], k=k)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "ndcg_at_2 = pd.DataFrame(\n",
    "    {\"score\": documents_with_relevance_df.groupby(\"context.span_id\").apply(_compute_ndcg, k=2)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5cb9d46-6952-4b1b-8865-ec580e082dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "precision_at_2 = pd.DataFrame(\n",
    "    {\n",
    "        \"score\": documents_with_relevance_df.groupby(\"context.span_id\").apply(\n",
    "            lambda x: x.eval_score[:2].sum(skipna=False) / 2\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff64b993-43fe-4c73-8a8c-e1fcca003e24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05ab7bba191afaf8</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0f9642f8f922b85c</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138cff6cfd0166ae</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318b8d51f79d1ba7</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32d03214d19bc42e</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  score\n",
       "context.span_id        \n",
       "05ab7bba191afaf8    0.5\n",
       "0f9642f8f922b85c    0.5\n",
       "138cff6cfd0166ae    0.5\n",
       "318b8d51f79d1ba7    0.5\n",
       "32d03214d19bc42e    0.5"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566e750c-aeca-42d3-9817-62a6d0face0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hit = pd.DataFrame(\n",
    "    {\n",
    "        \"hit\": documents_with_relevance_df.groupby(\"context.span_id\").apply(\n",
    "            lambda x: x.eval_score[:2].sum(skipna=False) > 0\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeffcff2-eb89-4382-9e45-03b26b630335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>precision@2_score</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ebed2652caff587f</th>\n",
       "      <td>What information is available in the context?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ae9aac0c4949b401</th>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9b2b9bef04cb96db</th>\n",
       "      <td>What is the participatory anthropic principle proposed by Wheeler?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45a12956917bde09</th>\n",
       "      <td>What is the 'substantial factor' test and which courts have adopted it?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0f9642f8f922b85c</th>\n",
       "      <td>What is the 'substantial factor' test and which courts have adopted it?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78bdd762d353b9fe</th>\n",
       "      <td>What is the perspective proposed by some theorists regarding consciousness and reality?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d06ed94a742f4e57</th>\n",
       "      <td>What is the perspective proposed by some theorists regarding consciousness and reality?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9b8c7e06be1bfc35</th>\n",
       "      <td>What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32d03214d19bc42e</th>\n",
       "      <td>What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbed08801c39da3</th>\n",
       "      <td>What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecd82126ed49017c</th>\n",
       "      <td>What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bae67fae1215f057</th>\n",
       "      <td>According to the context information, what is the implication of consciousness being primary?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39d2935169497c28</th>\n",
       "      <td>According to the context information, what is the implication of consciousness being primary?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb7f8b2584fdc446</th>\n",
       "      <td>What is the traditional causation standard for algorithmic influence assessment and how has it been modified?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138cff6cfd0166ae</th>\n",
       "      <td>What is the traditional causation standard for algorithmic influence assessment and how has it been modified?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1d3ca8777bed356</th>\n",
       "      <td>How does the perspective of consciousness being fundamental to reality challenge materialist and dualist frameworks?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952ca657d79aa345</th>\n",
       "      <td>How does the perspective of consciousness being fundamental to reality challenge materialist and dualist frameworks?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9fc98aff483ab4b5</th>\n",
       "      <td>What is the definition of Category A systems as per Appendix II-B?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4b2b452be05e248</th>\n",
       "      <td>What is the definition of Category A systems as per Appendix II-B?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6d8ea8a7ae1311fe</th>\n",
       "      <td>What are strong interactions in the context of quantum chromodynamics (QCD)?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c43a86ba07961678</th>\n",
       "      <td>What are strong interactions in the context of quantum chromodynamics (QCD)?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d981cc23f00dd3b6</th>\n",
       "      <td>Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318b8d51f79d1ba7</th>\n",
       "      <td>Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4e1039a9eb38a695</th>\n",
       "      <td>What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8bbc628462cffbef</th>\n",
       "      <td>What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afdcf25fdb61e22e</th>\n",
       "      <td>What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6000c45437efaa</th>\n",
       "      <td>What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05ab7bba191afaf8</th>\n",
       "      <td>What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78e436e679a367b4</th>\n",
       "      <td>What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91e8c032042a927b</th>\n",
       "      <td>What is the role of quarks and gluons in quantum chromodynamics (QCD)?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547e85d8f53a55d6</th>\n",
       "      <td>What is the role of quarks and gluons in quantum chromodynamics (QCD)?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                              attributes.input.value  ...    hit\n",
       "context.span_id                                                                                                                                                                                       ...       \n",
       "ebed2652caff587f                                                                                                                                       What information is available in the context?  ...  False\n",
       "ae9aac0c4949b401                                                                                                                  What is the participatory anthropic principle proposed by Wheeler?  ...   True\n",
       "9b2b9bef04cb96db                                                                                                                  What is the participatory anthropic principle proposed by Wheeler?  ...   True\n",
       "45a12956917bde09                                                                                                             What is the 'substantial factor' test and which courts have adopted it?  ...   True\n",
       "0f9642f8f922b85c                                                                                                             What is the 'substantial factor' test and which courts have adopted it?  ...   True\n",
       "78bdd762d353b9fe                                                                                             What is the perspective proposed by some theorists regarding consciousness and reality?  ...   True\n",
       "d06ed94a742f4e57                                                                                             What is the perspective proposed by some theorists regarding consciousness and reality?  ...   True\n",
       "9b8c7e06be1bfc35                                                What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?  ...   True\n",
       "32d03214d19bc42e                                                What is the requirement for operators regarding documentation of decision paths for autonomous actions affecting Category A systems?  ...   True\n",
       "ffbed08801c39da3                                                                                                     What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?  ...   True\n",
       "ecd82126ed49017c                                                                                                     What is the Standard Model's conceptualization of quantum chromodynamics (QCD)?  ...   True\n",
       "bae67fae1215f057                                                                                       According to the context information, what is the implication of consciousness being primary?  ...   True\n",
       "39d2935169497c28                                                                                       According to the context information, what is the implication of consciousness being primary?  ...   True\n",
       "fb7f8b2584fdc446                                                                       What is the traditional causation standard for algorithmic influence assessment and how has it been modified?  ...   True\n",
       "138cff6cfd0166ae                                                                       What is the traditional causation standard for algorithmic influence assessment and how has it been modified?  ...   True\n",
       "d1d3ca8777bed356                                                                How does the perspective of consciousness being fundamental to reality challenge materialist and dualist frameworks?  ...   True\n",
       "952ca657d79aa345                                                                How does the perspective of consciousness being fundamental to reality challenge materialist and dualist frameworks?  ...   True\n",
       "9fc98aff483ab4b5                                                                                                                  What is the definition of Category A systems as per Appendix II-B?  ...   True\n",
       "f4b2b452be05e248                                                                                                                  What is the definition of Category A systems as per Appendix II-B?  ...   True\n",
       "6d8ea8a7ae1311fe                                                                                                        What are strong interactions in the context of quantum chromodynamics (QCD)?  ...   True\n",
       "c43a86ba07961678                                                                                                        What are strong interactions in the context of quantum chromodynamics (QCD)?  ...   True\n",
       "d981cc23f00dd3b6                                                    Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.  ...   True\n",
       "318b8d51f79d1ba7                                                    Does objective reality exist independent of observation? Explain your answer with reference to the context information provided.  ...   True\n",
       "4e1039a9eb38a695                                                                                  What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?  ...   True\n",
       "8bbc628462cffbef                                                                                  What is the Model Autonomous Systems Code and how does it relate to the 'substantial factor' test?  ...   True\n",
       "afdcf25fdb61e22e                                                                   What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?  ...   True\n",
       "cd6000c45437efaa                                                                   What is the difference between the emergent and fundamental perspectives of consciousness in relation to reality?  ...   True\n",
       "05ab7bba191afaf8  What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?  ...   True\n",
       "78e436e679a367b4  What is the subsection that specifies the requirement for operators to maintain comprehensive documentation of decision paths for autonomous actions affecting Category A systems?  ...   True\n",
       "91e8c032042a927b                                                                                                              What is the role of quarks and gluons in quantum chromodynamics (QCD)?  ...   True\n",
       "547e85d8f53a55d6                                                                                                              What is the role of quarks and gluons in quantum chromodynamics (QCD)?  ...   True\n",
       "\n",
       "[31 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrievals_df = px.Client().get_spans_dataframe(\n",
    "    \"span_kind == 'RETRIEVER' and input.value is not None\"\n",
    ")\n",
    "rag_evaluation_dataframe = pd.concat(\n",
    "    [\n",
    "        retrievals_df[\"attributes.input.value\"],\n",
    "        precision_at_2.add_prefix(\"precision@2_\"),\n",
    "        hit,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "rag_evaluation_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c3125bb-6226-43b8-a66e-dde995f64b0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "precision@2_score    0.677419\n",
       "hit                  0.967742\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate the scores across the retrievals\n",
    "results = rag_evaluation_dataframe.mean(numeric_only=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b8258b8-d516-4a63-bb6a-c555e998e220",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from phoenix.trace import DocumentEvaluations, SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(dataframe=precision_at_2, eval_name=\"precision@2\"),\n",
    "    DocumentEvaluations(dataframe=retrieved_documents_relevance_df, eval_name=\"relevance\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8829c8fe-9f75-4fda-9e0d-e79e1767c4cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(31, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phoenix.session.evaluation import get_qa_with_reference\n",
    "\n",
    "qa_with_reference_df = get_qa_with_reference(px.Client())\n",
    "qa_with_reference_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26280a8c-15f9-4640-88f5-05826dfab5f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff58094bdfe44e3bbdfba53514dffe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "run_evals |          | 0/93 (0.0%) | ⏳ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-0277931ab5644ffcb8ef3c6b3c755015\", \"tr-96f8de9c9e464738960d913b9a1a5389\", \"tr-6c36ac0120494629a972929664767293\", \"tr-91a53fbe0f47459c9cb51c3b4c8505ab\", \"tr-2c5f66f6921c41989a13f537023c3f6e\", \"tr-d80aaa5150454c40b6907d3978e3cd97\", \"tr-0df29604af5e46909cf7857abaeb936a\", \"tr-e07f6535c18140c6b7c3481945ab08b8\", \"tr-f1d78e6723f547e7acc0ea6dee7c3acf\", \"tr-8b12faff28dd4afba4a295b4ec7b3514\"]",
      "text/plain": [
       "[Trace(request_id=tr-0277931ab5644ffcb8ef3c6b3c755015), Trace(request_id=tr-96f8de9c9e464738960d913b9a1a5389), Trace(request_id=tr-6c36ac0120494629a972929664767293), Trace(request_id=tr-91a53fbe0f47459c9cb51c3b4c8505ab), Trace(request_id=tr-2c5f66f6921c41989a13f537023c3f6e), Trace(request_id=tr-d80aaa5150454c40b6907d3978e3cd97), Trace(request_id=tr-0df29604af5e46909cf7857abaeb936a), Trace(request_id=tr-e07f6535c18140c6b7c3481945ab08b8), Trace(request_id=tr-f1d78e6723f547e7acc0ea6dee7c3acf), Trace(request_id=tr-8b12faff28dd4afba4a295b4ec7b3514)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"from phoenix.evals import (\n",
    "    HallucinationEvaluator,\n",
    "    OpenAIModel,\n",
    "    LiteLLMModel,\n",
    "    QAEvaluator,\n",
    "    run_evals,\n",
    "    ToxicityEvaluator,\n",
    "    llm_classify,\n",
    "    llm_generate,\n",
    "    PromptTemplate\n",
    ")\n",
    "\n",
    "\n",
    "toxicity_evaluator = ToxicityEvaluator(LiteLLMModel(model=\"azure/gpt-35-turbo\"))\n",
    "qa_evaluator = QAEvaluator(LiteLLMModel(\n",
    "    model=\"azure/gpt-35-turbo\"\n",
    "))\n",
    "hallucination_evaluator = HallucinationEvaluator(LiteLLMModel(\n",
    "    model=\"azure/gpt-35-turbo\"\n",
    "))\n",
    "\n",
    "qa_correctness_eval_df, hallucination_eval_df,toxicity_eval_df = run_evals(\n",
    "    evaluators=[qa_evaluator, hallucination_evaluator,toxicity_evaluator],\n",
    "    dataframe=qa_with_reference_df,\n",
    "    provide_explanation=True,\n",
    "    concurrency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3679cc9d-3958-4a37-9fa2-186442668561",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8761f687366fd432</th>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "      <td>The answer correctly answers the question. It provides information about a regulation related to autonomous actions affecting certain systems (Category A systems) in the context of AI. It mentions that operators must maintain comprehensive documentation of decision paths for these autonomous actions. The answer also correctly states that the reference text does not provide information about philosophical questions, regulatory compliance across multiple jurisdictions, or impact on market dynamics and competitive positioning. Therefore, the answer is \"correct\". \\nLABEL: \"correct\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ae9aac0c4949b401</th>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "      <td>The question asks for the definition of the participatory anthropic principle proposed by Wheeler. The answer provides a direct quote from the reference text that explains the principle, stating that \"observers are necessary for the actualization of potential states.\" Therefore, the answer is correct as it directly answers the question with the relevant information from the reference text. \\nLABEL: \"correct\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b7b095866d7bd120</th>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "      <td>The question asks for the definition of the participatory anthropic principle proposed by Wheeler. The answer provides a clear and accurate definition of the principle, stating that it suggests observers are necessary for the actualization of potential states in objective reality and that consciousness plays a role in shaping the physical world. The reference text also supports this definition by mentioning Wheeler's participatory anthropic principle and its implications. Therefore, the answer is correct. \\nLABEL: \"correct\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45a12956917bde09</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>The answer correctly addresses the first part of the question by stating that the \"substantial factor\" test is adopted by some courts and is outlined in the Model Autonomous Systems Code. However, it does not provide information on which courts have adopted it. The answer also includes additional information on liability extending to third-party algorithm providers, but this is not directly related to the \"substantial factor\" test. Therefore, the answer is partially correct but incomplete. \\nLABEL: \"incorrect\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974abd3ebf286c28</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>0</td>\n",
       "      <td>The answer correctly defines the \"substantial factor\" test as a legal standard outlined in the Model Autonomous Systems Code that some courts have adopted. It also correctly explains that this test assesses whether an algorithmic system's influence was a significant or substantial factor in causing harm, as opposed to the traditional \"but for\" causation standard. The answer also mentions that some courts maintain the traditional standard with modifications for algorithmic influence assessment. Additionally, the answer provides a reference to support the information provided. However, the answer does not fully address the second part of the question, which asks which courts have adopted the test. Therefore, the answer is partially correct. \\nLABEL: \"incorrect\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        explanation\n",
       "context.span_id              ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "8761f687366fd432    correct  ...                                                                                                                                                                                           The answer correctly answers the question. It provides information about a regulation related to autonomous actions affecting certain systems (Category A systems) in the context of AI. It mentions that operators must maintain comprehensive documentation of decision paths for these autonomous actions. The answer also correctly states that the reference text does not provide information about philosophical questions, regulatory compliance across multiple jurisdictions, or impact on market dynamics and competitive positioning. Therefore, the answer is \"correct\". \\nLABEL: \"correct\"\n",
       "ae9aac0c4949b401    correct  ...                                                                                                                                                                                                                                                                                                                                                                        The question asks for the definition of the participatory anthropic principle proposed by Wheeler. The answer provides a direct quote from the reference text that explains the principle, stating that \"observers are necessary for the actualization of potential states.\" Therefore, the answer is correct as it directly answers the question with the relevant information from the reference text. \\nLABEL: \"correct\"\n",
       "b7b095866d7bd120    correct  ...                                                                                                                                                                                                                                                  The question asks for the definition of the participatory anthropic principle proposed by Wheeler. The answer provides a clear and accurate definition of the principle, stating that it suggests observers are necessary for the actualization of potential states in objective reality and that consciousness plays a role in shaping the physical world. The reference text also supports this definition by mentioning Wheeler's participatory anthropic principle and its implications. Therefore, the answer is correct. \\nLABEL: \"correct\"\n",
       "45a12956917bde09  incorrect  ...                                                                                                                                                                                                                                                                The answer correctly addresses the first part of the question by stating that the \"substantial factor\" test is adopted by some courts and is outlined in the Model Autonomous Systems Code. However, it does not provide information on which courts have adopted it. The answer also includes additional information on liability extending to third-party algorithm providers, but this is not directly related to the \"substantial factor\" test. Therefore, the answer is partially correct but incomplete. \\nLABEL: \"incorrect\"\n",
       "974abd3ebf286c28  incorrect  ...  The answer correctly defines the \"substantial factor\" test as a legal standard outlined in the Model Autonomous Systems Code that some courts have adopted. It also correctly explains that this test assesses whether an algorithmic system's influence was a significant or substantial factor in causing harm, as opposed to the traditional \"but for\" causation standard. The answer also mentions that some courts maintain the traditional standard with modifications for algorithmic influence assessment. Additionally, the answer provides a reference to support the information provided. However, the answer does not fully address the second part of the question, which asks which courts have adopted the test. Therefore, the answer is partially correct. \\nLABEL: \"incorrect\"\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_correctness_eval_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a48a38a5-2d87-4144-867c-4e4e2ce79d6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8761f687366fd432</th>\n",
       "      <td>factual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The answer is factual. The reference text provides information about a regulation related to autonomous actions affecting certain systems (Category A systems) in the context of AI. It mentions that operators must maintain comprehensive documentation of decision paths for these autonomous actions. The answer accurately summarizes this information and does not contain any false information. Additionally, the answer acknowledges that the reference text does not provide information about philosophical questions, regulatory compliance across multiple jurisdictions, or impact on market dynamics and competitive positioning. Therefore, the answer is factual. \\nLABEL: factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ae9aac0c4949b401</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The answer is factual. The reference text discusses Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The answer accurately quotes this principle and provides additional information from the reference text about the paradox created by the illusion of individuality. Therefore, the answer is based on the reference text and contains factual information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b7b095866d7bd120</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The answer is factual. The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states in objective reality and that consciousness plays a role in shaping the physical world. The answer accurately reflects this information and does not contain any false information or assumptions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45a12956917bde09</th>\n",
       "      <td>factual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The answer provides factual information to the query based on the reference text. The reference text states that some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, and this is reiterated in the answer. Additionally, the reference text mentions that liability may extend to third-party algorithm providers under specific conditions, which is also accurately reflected in the answer. Therefore, the answer is factual. \\nLABEL: \"factual\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974abd3ebf286c28</th>\n",
       "      <td>factual</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The answer correctly defines the \"substantial factor\" test as a legal standard outlined in the Model Autonomous Systems Code that some courts have adopted. It also correctly explains that this test assesses whether an algorithmic system's influence was a significant or substantial factor in causing harm, as opposed to the traditional \"but for\" causation standard. The reference text supports this information. Additionally, the answer provides further information from the reference text that liability may extend to third-party algorithm providers under specific conditions. Therefore, the answer is factual. \\nLABEL: factual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         label  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          explanation\n",
       "context.span_id                 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "8761f687366fd432       factual  ...  The answer is factual. The reference text provides information about a regulation related to autonomous actions affecting certain systems (Category A systems) in the context of AI. It mentions that operators must maintain comprehensive documentation of decision paths for these autonomous actions. The answer accurately summarizes this information and does not contain any false information. Additionally, the answer acknowledges that the reference text does not provide information about philosophical questions, regulatory compliance across multiple jurisdictions, or impact on market dynamics and competitive positioning. Therefore, the answer is factual. \\nLABEL: factual\n",
       "ae9aac0c4949b401  NOT_PARSABLE  ...                                                                                                                                                                                                                                                   The answer is factual. The reference text discusses Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states. The answer accurately quotes this principle and provides additional information from the reference text about the paradox created by the illusion of individuality. Therefore, the answer is based on the reference text and contains factual information.\n",
       "b7b095866d7bd120  NOT_PARSABLE  ...                                                                                                                                                                                                                                                                                                             The answer is factual. The reference text mentions Wheeler's participatory anthropic principle, which suggests that observers are necessary for the actualization of potential states in objective reality and that consciousness plays a role in shaping the physical world. The answer accurately reflects this information and does not contain any false information or assumptions.\n",
       "45a12956917bde09       factual  ...                                                                                                                                                                                                The answer provides factual information to the query based on the reference text. The reference text states that some courts have adopted the \"substantial factor\" test outlined in the Model Autonomous Systems Code, and this is reiterated in the answer. Additionally, the reference text mentions that liability may extend to third-party algorithm providers under specific conditions, which is also accurately reflected in the answer. Therefore, the answer is factual. \\nLABEL: \"factual\"\n",
       "974abd3ebf286c28       factual  ...                                                 The answer correctly defines the \"substantial factor\" test as a legal standard outlined in the Model Autonomous Systems Code that some courts have adopted. It also correctly explains that this test assesses whether an algorithmic system's influence was a significant or substantial factor in causing harm, as opposed to the traditional \"but for\" causation standard. The reference text supports this information. Additionally, the answer provides further information from the reference text that liability may extend to third-party algorithm providers under specific conditions. Therefore, the answer is factual. \\nLABEL: factual\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_eval_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a0bdc0f-8155-4c6c-9d3b-bc60145e0479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8761f687366fd432</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not contain any hateful statements, demeaning or disparaging language, or threats of physical or emotional violence. It is a neutral question asking about available information in a given context. Therefore, the text is non-toxic.\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ae9aac0c4949b401</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. It does not make any hateful statements, demean or disparage anyone, use inappropriate language, or threaten physical or emotional violence. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b7b095866d7bd120</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. It does not make any hateful statements, demean or disparage anyone, use inappropriate language, or threaten physical or emotional violence. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45a12956917bde09</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a straightforward question about a legal concept and does not contain any language that could be considered hateful, demeaning, or threatening. It is not inappropriate in any way and does not disparage any individual or group. Therefore, the text is non-toxic.\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974abd3ebf286c28</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a straightforward question about a legal concept and does not contain any language that could be considered hateful, demeaning, or threatening. It is not inappropriate in any way and does not disparage any individual or group. Therefore, the text is non-toxic.\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78bdd762d353b9fe</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a neutral question about a theoretical perspective on consciousness and reality. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41562a5c7695ab5b</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a neutral question about a theoretical perspective on consciousness and reality. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9b8c7e06be1bfc35</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a technical question regarding documentation requirements for operators of autonomous actions affecting Category A systems. There is no language or sentiment that could be considered toxic, hateful, demeaning, or threatening. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70c0aeb405a8d3ba</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a technical question regarding documentation requirements for operators of autonomous actions affecting Category A systems. There is no language or sentiment that could be considered toxic, hateful, demeaning, or threatening. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbed08801c39da3</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b1813cecb5f92c0</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bae67fae1215f057</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is not toxic as it is a neutral question that does not contain any hateful or inappropriate language. It simply asks for an interpretation of a concept. \\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac7451fe00285898</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is not toxic as it is a neutral question that does not contain any hateful or inappropriate language. It simply asks for an interpretation of a concept. \\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb7f8b2584fdc446</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a neutral question about the traditional causation standard for algorithmic influence assessment and how it has been modified. There are no hateful statements, inappropriate language, or threats of violence. Therefore, the text is non-toxic. \\n\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6c26f75a26d62128</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a neutral question about the traditional causation standard for algorithmic influence assessment and how it has been modified. There are no hateful statements, inappropriate language, or threats of violence. Therefore, the text is non-toxic. \\n\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1d3ca8777bed356</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a neutral and academic question about the relationship between consciousness and reality. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad04b7796a701989</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a neutral and academic question about the relationship between consciousness and reality. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9fc98aff483ab4b5</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a straightforward question about the definition of a technical term and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39e9d2775e4a0ee3</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a straightforward question about the definition of a technical term and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6d8ea8a7ae1311fe</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62d42b25bb999b06</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d981cc23f00dd3b6</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a neutral question that does not contain any language or sentiments that could be considered toxic. It is a philosophical inquiry that does not target or demean any individual or group. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c9ea6c0dd414fdfb</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a neutral question that does not contain any language or sentiments that could be considered toxic. It is a philosophical inquiry that does not target or demean any individual or group. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4e1039a9eb38a695</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not contain any language that is hateful, demeaning, or threatening. It is a neutral question about a technical topic. Therefore, the text is non-toxic. \\n\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb5bf12bfb379ff5</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not contain any language that is hateful, demeaning, or threatening. It is a neutral question about a technical topic. Therefore, the text is non-toxic. \\n\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afdcf25fdb61e22e</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not contain any language or sentiments that could be considered toxic. It is a neutral question about the difference between two perspectives on consciousness. \\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a259642b0572dcb9</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not contain any language or sentiments that could be considered toxic. It is a neutral question about the difference between two perspectives on consciousness. \\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05ab7bba191afaf8</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a technical question about a subsection related to autonomous actions affecting Category A systems. There is no language or sentiment that could be considered toxic or offensive. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91e0d941497f3115</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a technical question about a subsection related to autonomous actions affecting Category A systems. There is no language or sentiment that could be considered toxic or offensive. Therefore, the label is \"non-toxic\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91e8c032042a927b</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a scientific question about the role of quarks and gluons in quantum chromodynamics. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7692778d469428d7</th>\n",
       "      <td>non-toxic</td>\n",
       "      <td>0</td>\n",
       "      <td>The text is a scientific question about the role of quarks and gluons in quantum chromodynamics. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label  ...                                                                                                                                                                                                                                                                                                                          explanation\n",
       "context.span_id              ...                                                                                                                                                                                                                                                                                                                                     \n",
       "8761f687366fd432  non-toxic  ...                                                               The text does not contain any hateful statements, demeaning or disparaging language, or threats of physical or emotional violence. It is a neutral question asking about available information in a given context. Therefore, the text is non-toxic.\\nLABEL: non-toxic\n",
       "ae9aac0c4949b401  non-toxic  ...  The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. It does not make any hateful statements, demean or disparage anyone, use inappropriate language, or threaten physical or emotional violence. Therefore, the label is \"non-toxic\".\n",
       "b7b095866d7bd120  non-toxic  ...  The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. It does not make any hateful statements, demean or disparage anyone, use inappropriate language, or threaten physical or emotional violence. Therefore, the label is \"non-toxic\".\n",
       "45a12956917bde09  non-toxic  ...                                   The text is a straightforward question about a legal concept and does not contain any language that could be considered hateful, demeaning, or threatening. It is not inappropriate in any way and does not disparage any individual or group. Therefore, the text is non-toxic.\\nLABEL: non-toxic\n",
       "974abd3ebf286c28  non-toxic  ...                                   The text is a straightforward question about a legal concept and does not contain any language that could be considered hateful, demeaning, or threatening. It is not inappropriate in any way and does not disparage any individual or group. Therefore, the text is non-toxic.\\nLABEL: non-toxic\n",
       "78bdd762d353b9fe  non-toxic  ...                                 The text is a neutral question about a theoretical perspective on consciousness and reality. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic\n",
       "41562a5c7695ab5b  non-toxic  ...                                 The text is a neutral question about a theoretical perspective on consciousness and reality. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic\n",
       "9b8c7e06be1bfc35  non-toxic  ...                                                   The text is a technical question regarding documentation requirements for operators of autonomous actions affecting Category A systems. There is no language or sentiment that could be considered toxic, hateful, demeaning, or threatening. Therefore, the label is \"non-toxic\".\n",
       "70c0aeb405a8d3ba  non-toxic  ...                                                   The text is a technical question regarding documentation requirements for operators of autonomous actions affecting Category A systems. There is no language or sentiment that could be considered toxic, hateful, demeaning, or threatening. Therefore, the label is \"non-toxic\".\n",
       "ffbed08801c39da3  non-toxic  ...                                                                                                                                               The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".\n",
       "1b1813cecb5f92c0  non-toxic  ...                                                                                                                                               The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".\n",
       "bae67fae1215f057  non-toxic  ...                                                                                                                                                 The text is not toxic as it is a neutral question that does not contain any hateful or inappropriate language. It simply asks for an interpretation of a concept. \\nLABEL: non-toxic\n",
       "ac7451fe00285898  non-toxic  ...                                                                                                                                                 The text is not toxic as it is a neutral question that does not contain any hateful or inappropriate language. It simply asks for an interpretation of a concept. \\nLABEL: non-toxic\n",
       "fb7f8b2584fdc446  non-toxic  ...                                                   The text is a neutral question about the traditional causation standard for algorithmic influence assessment and how it has been modified. There are no hateful statements, inappropriate language, or threats of violence. Therefore, the text is non-toxic. \\n\\nLABEL: non-toxic\n",
       "6c26f75a26d62128  non-toxic  ...                                                   The text is a neutral question about the traditional causation standard for algorithmic influence assessment and how it has been modified. There are no hateful statements, inappropriate language, or threats of violence. Therefore, the text is non-toxic. \\n\\nLABEL: non-toxic\n",
       "d1d3ca8777bed356  non-toxic  ...                        The text is a neutral and academic question about the relationship between consciousness and reality. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic\n",
       "ad04b7796a701989  non-toxic  ...                        The text is a neutral and academic question about the relationship between consciousness and reality. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic\n",
       "9fc98aff483ab4b5  non-toxic  ...                                                                                                                                 The text is a straightforward question about the definition of a technical term and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".\n",
       "39e9d2775e4a0ee3  non-toxic  ...                                                                                                                                 The text is a straightforward question about the definition of a technical term and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".\n",
       "6d8ea8a7ae1311fe  non-toxic  ...                                                                                                                                               The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".\n",
       "62d42b25bb999b06  non-toxic  ...                                                                                                                                               The text is a straightforward question about a scientific concept and does not contain any language or sentiments that could be considered toxic. Therefore, the label is \"non-toxic\".\n",
       "d981cc23f00dd3b6  non-toxic  ...                                                                                           The text is a neutral question that does not contain any language or sentiments that could be considered toxic. It is a philosophical inquiry that does not target or demean any individual or group. Therefore, the label is \"non-toxic\".\n",
       "c9ea6c0dd414fdfb  non-toxic  ...                                                                                           The text is a neutral question that does not contain any language or sentiments that could be considered toxic. It is a philosophical inquiry that does not target or demean any individual or group. Therefore, the label is \"non-toxic\".\n",
       "4e1039a9eb38a695  non-toxic  ...                                                                                                                                          The text does not contain any language that is hateful, demeaning, or threatening. It is a neutral question about a technical topic. Therefore, the text is non-toxic. \\n\\nLABEL: non-toxic\n",
       "eb5bf12bfb379ff5  non-toxic  ...                                                                                                                                          The text does not contain any language that is hateful, demeaning, or threatening. It is a neutral question about a technical topic. Therefore, the text is non-toxic. \\n\\nLABEL: non-toxic\n",
       "afdcf25fdb61e22e  non-toxic  ...                                                                                                                                     The text does not contain any language or sentiments that could be considered toxic. It is a neutral question about the difference between two perspectives on consciousness. \\nLABEL: non-toxic\n",
       "a259642b0572dcb9  non-toxic  ...                                                                                                                                     The text does not contain any language or sentiments that could be considered toxic. It is a neutral question about the difference between two perspectives on consciousness. \\nLABEL: non-toxic\n",
       "05ab7bba191afaf8  non-toxic  ...                                                                                                  The text is a technical question about a subsection related to autonomous actions affecting Category A systems. There is no language or sentiment that could be considered toxic or offensive. Therefore, the label is \"non-toxic\".\n",
       "91e0d941497f3115  non-toxic  ...                                                                                                  The text is a technical question about a subsection related to autonomous actions affecting Category A systems. There is no language or sentiment that could be considered toxic or offensive. Therefore, the label is \"non-toxic\".\n",
       "91e8c032042a927b  non-toxic  ...                             The text is a scientific question about the role of quarks and gluons in quantum chromodynamics. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic\n",
       "7692778d469428d7  non-toxic  ...                             The text is a scientific question about the role of quarks and gluons in quantum chromodynamics. It does not contain any language that demeans or disparages another user, uses inappropriate language, or threatens physical or emotional violence. Therefore, the text is non-toxic.\\nLABEL: non-toxic\n",
       "\n",
       "[31 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e53c89b2-3a08-4124-8059-fb5c8c4eaa7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "score    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_eval_df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "319378ae-1622-41e0-acd7-42176999c777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "score    0.709677\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_correctness_eval_df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f495b0d6-2a61-4ef7-b1be-4bd920bd41e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "score    0.032258\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_eval_df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7635174a-8f34-4f3b-863a-3fb37d0e92b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a3dffe0a4241a8a23b6a366ac83021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_classify |          | 0/31 (0.0%) | ⏳ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-fff970eadf4648b9ad7eb5e952b0bf16\", \"tr-99c6a1b4b9ff40719c025b0073c8d35e\", \"tr-eeba9d7d278641518d7bb40e5b08c5ca\", \"tr-e8c30033987b465f80fd4b2391902591\", \"tr-330c03b3427b49ab8d5ac3d768392c05\", \"tr-af1c99579a344ced9dd31a1cf17bf537\", \"tr-fd0924c88aae46c9a0b558fada8af668\", \"tr-bf4e7553d1354baeb0fa02ebf82b705a\", \"tr-8d384c284c7f4f259dbc6cb10986ac60\", \"tr-301f1e2432f94095bf99f1a9b83ffdb1\"]",
      "text/plain": [
       "[Trace(request_id=tr-fff970eadf4648b9ad7eb5e952b0bf16), Trace(request_id=tr-99c6a1b4b9ff40719c025b0073c8d35e), Trace(request_id=tr-eeba9d7d278641518d7bb40e5b08c5ca), Trace(request_id=tr-e8c30033987b465f80fd4b2391902591), Trace(request_id=tr-330c03b3427b49ab8d5ac3d768392c05), Trace(request_id=tr-af1c99579a344ced9dd31a1cf17bf537), Trace(request_id=tr-fd0924c88aae46c9a0b558fada8af668), Trace(request_id=tr-bf4e7553d1354baeb0fa02ebf82b705a), Trace(request_id=tr-8d384c284c7f4f259dbc6cb10986ac60), Trace(request_id=tr-301f1e2432f94095bf99f1a9b83ffdb1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Custom classification using llm_classify\n",
    "# Example: Evaluate answer completeness\n",
    "completeness_template = PromptTemplate(\n",
    "    \"\"\"\n",
    "    Question: {input}\n",
    "    Answer: {output}\n",
    "    Reference: {reference}\n",
    "    \n",
    "    Evaluate if the answer is complete relative to the available reference information.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "completeness_eval = llm_classify(\n",
    "    dataframe=qa_with_reference_df,\n",
    "    model=LiteLLMModel(model=\"azure/gpt-35-turbo\"),\n",
    "    template=completeness_template,\n",
    "    rails=[\"complete\", \"partially_complete\", \"incomplete\"],\n",
    "    provide_explanation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed449d83-b30b-4ea7-b4fc-f120691fdd31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>explanation</th>\n",
       "      <th>exceptions</th>\n",
       "      <th>execution_status</th>\n",
       "      <th>execution_seconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8761f687366fd432</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>The answer is complete relative to the available reference information. It accurately summarizes the information provided in the context and does not include any additional information not mentioned in the reference.</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>28.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ae9aac0c4949b401</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>The answer is complete and accurately summarizes the reference information provided. It explains that Wheeler's participatory anthropic principle suggests that observers are necessary for the actualization of potential states, and raises the question of whether objective reality exists independent of observation if consciousness is primary. The answer also mentions the paradox created by the illusion of individuality, which is necessary for practical functioning.</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>28.055479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b7b095866d7bd120</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>The answer is complete relative to the available reference information. It provides a clear explanation of the participatory anthropic principle proposed by Wheeler and includes a relevant reference.</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>28.055510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45a12956917bde09</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>The answer is complete as it provides a definition of the substantial factor test and mentions that some courts have adopted it, while others have modified traditional causation standards for algorithmic influence assessment. It also references a source that suggests liability for third-party algorithm providers under certain conditions.</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>28.055533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974abd3ebf286c28</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>The answer is complete as it defines the 'substantial factor' test, mentions the Model Autonomous Systems Code, and states that some courts have adopted it while others have modified the traditional causation standard. It also provides a reference to support this information. Additionally, it mentions a suggestion from Regional Authority (2023) regarding liability for third-party algorithm providers.</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>28.055553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         label  ... execution_seconds\n",
       "context.span_id                 ...                  \n",
       "8761f687366fd432  NOT_PARSABLE  ...         28.054600\n",
       "ae9aac0c4949b401  NOT_PARSABLE  ...         28.055479\n",
       "b7b095866d7bd120  NOT_PARSABLE  ...         28.055510\n",
       "45a12956917bde09  NOT_PARSABLE  ...         28.055533\n",
       "974abd3ebf286c28  NOT_PARSABLE  ...         28.055553\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dc708ef-8deb-4c38-a37d-2e2dd1ba48de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cd84a9170b447996f6823c2589b66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llm_generate |          | 0/31 (0.0%) | ⏳ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-1126eaf0e3e8415a93a6d055bafaf832\", \"tr-4189977e16434c50a45035fd377e9e91\", \"tr-78400f503cd747b0ae7a127d48780bd3\", \"tr-39e4a69319264be58910061b1a6c08bb\", \"tr-42aed44b691e471ebbe3d8a502cbf63b\", \"tr-478beb0e7543451c8d58cce02c50a828\", \"tr-126579edc58740309278a4599dd32c6a\", \"tr-862c842d3c6c4b6babe62ceabf8b4872\", \"tr-8765cb5b60eb42df9984b62ee5283439\", \"tr-65c69e4bfce54f8e815bae334ae47075\"]",
      "text/plain": [
       "[Trace(request_id=tr-1126eaf0e3e8415a93a6d055bafaf832), Trace(request_id=tr-4189977e16434c50a45035fd377e9e91), Trace(request_id=tr-78400f503cd747b0ae7a127d48780bd3), Trace(request_id=tr-39e4a69319264be58910061b1a6c08bb), Trace(request_id=tr-42aed44b691e471ebbe3d8a502cbf63b), Trace(request_id=tr-478beb0e7543451c8d58cce02c50a828), Trace(request_id=tr-126579edc58740309278a4599dd32c6a), Trace(request_id=tr-862c842d3c6c4b6babe62ceabf8b4872), Trace(request_id=tr-8765cb5b60eb42df9984b62ee5283439), Trace(request_id=tr-65c69e4bfce54f8e815bae334ae47075)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CLARITY_SCORE_TEMPLATE = \"\"\"\n",
    "You are evaluating the clarity of an AI response on a scale of 1-10.\n",
    "1 = completely unclear, confusing\n",
    "10 = crystal clear, perfectly understandable\n",
    "\n",
    "[BEGIN DATA]\n",
    "AI Response: {output}\n",
    "[END DATA]\n",
    "\n",
    "Please return the clarity score in format: \"the score is: X\"\n",
    "Return only this score, no other text.\n",
    "\"\"\"\n",
    "\n",
    "def clarity_score_parser(output, row_index):\n",
    "    import re\n",
    "    pattern = r\"score is.*?([0-9]|10)\"\n",
    "    match = re.search(pattern, output, re.IGNORECASE)\n",
    "    if match:\n",
    "        return {\"clarity_score\": float(match.group(1))}\n",
    "    return {\"clarity_score\": None}\n",
    "\n",
    "clarity_scores = llm_generate(\n",
    "    dataframe=qa_with_reference_df,\n",
    "    template=CLARITY_SCORE_TEMPLATE,\n",
    "    model=LiteLLMModel(model=\"azure/gpt-35-turbo\"),\n",
    "    output_parser=clarity_score_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ec83239-938c-4276-9188-47e8290387a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(31, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_with_reference_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca1d574-0a60-4d6b-b199-cbdfe4fe1410",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clarity_scores.rename(columns={\"clarity_score\": \"score\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7017b47e-5ec6-46d3-b437-13fa294b2ebf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(dataframe=qa_correctness_eval_df, eval_name=\"Q&A Correctness\"),\n",
    "    SpanEvaluations(dataframe=hallucination_eval_df, eval_name=\"Hallucination\"),\n",
    "    SpanEvaluations(dataframe=toxicity_eval_df, eval_name=\"Toxicity\"),\n",
    "    SpanEvaluations(dataframe=completeness_eval, eval_name=\"Completeness\"),\n",
    "    SpanEvaluations(dataframe=clarity_scores, eval_name=\"Clarity\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Phoenix eval",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
